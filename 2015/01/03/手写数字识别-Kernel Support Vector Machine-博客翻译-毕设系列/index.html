
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列 | Tim Chan&#39;s Blog!</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Tim Chan">
    
    <meta name="description" content="写在前面的话

本篇博文是翻译自Code Project上的César de Souza教授的关于用Kernel Support Vector Machine手写数字识别的博客。认真学习借鉴一下。
出处：Handwriting Recognition Revisited: Kernel Suppor">
    
    
    
    
    <link rel="alternative" href="/atom.xml" title="Tim Chan&#39;s Blog!" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">

</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Tim Chan&#39;s Blog!" title="Tim Chan&#39;s Blog!"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Tim Chan&#39;s Blog!">Tim Chan&#39;s Blog!</a></h1>
				<h2 class="blog-motto">记录生活点滴！</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于我</a></li>
					
						<li><a href="https://pomotodo.com/app/">ToDo</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:tim4chan.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/01/03/手写数字识别-Kernel Support Vector Machine-博客翻译-毕设系列/" title="手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列" itemprop="url">手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列</a>
  </h1>
  <p class="article-author">By
       
		<a href="http://tim4chan.com/about" title="Tim Chan" target="_blank" itemprop="author">Tim Chan</a>
		
  <p class="article-time">
    <time datetime="2015-01-03T06:29:02.000Z" itemprop="datePublished"> Published Jan 3 2015</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#写在前面的话"><span class="toc-number">1.</span> <span class="toc-text">写在前面的话</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#博文正文"><span class="toc-number">2.</span> <span class="toc-text">博文正文</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">2.1.</span> <span class="toc-text">简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#支持向量机"><span class="toc-number">2.1.1.</span> <span class="toc-text">支持向量机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基于核函数的支持向量机"><span class="toc-number">2.1.2.</span> <span class="toc-text">基于核函数的支持向量机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多分类的支持向量机"><span class="toc-number">2.1.3.</span> <span class="toc-text">多分类的支持向量机</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#源代码"><span class="toc-number">2.2.</span> <span class="toc-text">源代码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#支持向量机-1"><span class="toc-number">2.2.1.</span> <span class="toc-text">支持向量机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#训练算法"><span class="toc-number">2.2.2.</span> <span class="toc-text">训练算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数字识别"><span class="toc-number">2.3.</span> <span class="toc-text">数字识别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#UCI的光学数字数据集"><span class="toc-number">2.3.1.</span> <span class="toc-text">UCI的光学数字数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基于多分类的SVM的数字分类器"><span class="toc-number">2.3.2.</span> <span class="toc-text">基于多分类的SVM的数字分类器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#应用例子"><span class="toc-number">2.4.</span> <span class="toc-text">应用例子</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#学习"><span class="toc-number">2.4.1.</span> <span class="toc-text">学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结果"><span class="toc-number">2.4.2.</span> <span class="toc-text">结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">2.5.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#继续阅读"><span class="toc-number">2.6.</span> <span class="toc-text">继续阅读</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-number">2.7.</span> <span class="toc-text">参考</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#后记"><span class="toc-number">3.</span> <span class="toc-text">后记</span></a></li></ol>
		
		</div>
		
		<h1 id="写在前面的话">写在前面的话</h1>
<ul>
<li>本篇博文是翻译自Code Project上的<a href="http://www.codeproject.com/script/Membership/View.aspx?mid=1841592" target="_blank" rel="external">César de Souza</a>教授的关于用Kernel Support Vector Machine手写数字识别的博客。认真学习借鉴一下。</li>
<li>出处：<a href="http://www.codeproject.com/Articles/106583/Handwriting-Recognition-Revisited-Kernel-Support-V" target="_blank" rel="external">Handwriting Recognition Revisited: Kernel Support Vector Machines</a></li>
</ul>
<h1 id="博文正文">博文正文</h1>
<ul>
<li>在上一篇文章中，我们讨论了怎么利用基于核函数的辨别分析(Kernel Discriminant Analysis)的方法来解决手写数字识别的问题。在这里，我们将要讨论如何利用基于核函数的支持向量机(Kernel Support Vector Machine)的一些技巧来解决手写数字的识别问题。</li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png" alt=""><a href="http://www.codeproject.com/KB/recipes/handwriting-svm/accord-handwritting-svm-src.zip" target="_blank" rel="external">Download source code - 584 KB </a></li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png" alt=""><a href="http://www.codeproject.com/KB/recipes/handwriting-svm/accord-handwritting-svm-bin.zip" target="_blank" rel="external">Download sample application - 522 KB</a></li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/download.png" alt="">Download the <a href="http://accord-framework.net/" target="_blank" rel="external">Accord.NET Machine Learning Framework.</a></li>
<li>由于在最新的代码库中，它通常包含了最新的功能增强和修正，所以请下载  最新的<a href="http://accord-framework.net/" target="_blank" rel="external">Accord.NET Framework</a>.</li>
<li><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/font.png" alt=""></li>
</ul>
<h2 id="简介">简介</h2>
<ul>
<li>在上一篇文章中，我想向大家展示怎么用<a href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" target="_blank" rel="external">核判别分析法</a>来解决手写数字识别的问题。但是，我发现自己并没有更多的关注手写数字识别的问题，因为我把焦点都放在了KDA方法上了，而不是识别问题本身。在本篇文章中，我会给大家展示一个更好的方法来解决数字识别的问题。</li>
<li>核判别分析方法有自己的问题集。尽管它在处理高维度的数据是没有任何问题，但当样本的数量达到O(n³)，它就显得有些无能为力了。另外一个更严重的问题是在模型评估过程中核判别分析方法需要载入全部数据集，这样令它很难推广(例如嵌入式系统)。</li>
<li>在上一篇文章的最后，我提到了SVM其实是一种解决数字识别的更好的方法。SVM的一个优点是它们的解决问题的方法比较单一，不像KDA,它们在数据评估的过程中不需要载入全部数据集，而只是需要非常小部分的数据。这部分数据就是我们所通常称的”支持向量”。</li>
</ul>
<h3 id="支持向量机">支持向量机</h3>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Support_vector_machine" target="_blank" rel="external">支持向量机</a>是属于<a href="http://en.wikipedia.org/wiki/Supervised_learning" target="_blank" rel="external">监督学习</a>方法中的一种，它既可以用作<a href="http://en.wikipedia.org/wiki/Statistical_classification" target="_blank" rel="external">分类</a>，也可以用做<a href="http://en.wikipedia.org/wiki/Regression_analysis" target="_blank" rel="external">回归</a>。简单的说，给定一个训练数据样本，其中的每条记录都有一个标记变量，它标记着本条记录是属于哪一个分类的(现在讨论的是二类分类器)，然后数据集通过SVM分类器进行训练得到一个<a href="http://en.wikipedia.org/wiki/Classifier_(mathematics" target="_blank" rel="external">决策模型</a>)，这个模型可以预测新进来的一条记录是属于两个分类中的哪一种。如果样本中的每条记录是落在空间上的某个点，那么一个SVM的线性分类器可以看做是空间中的一个分界，把空间分成两类，这样我们希望把样本分成两类的清晰的间隔，它越宽越好。新的样本点看它落在间隔的那一边上就可以预测它属于那一类的了。<br><br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/SVM-1.png" alt=""></li>
<li>一个线性SVM是由给定的支持向量<strong>z</strong>集合和权重<strong>w</strong>集合组成。由N个支持向量z1,z2…zN和w1,w2…wN构成的支持向量机输出的计算公式是：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/SVM-fornular-1.png" alt=""></li>
<li>一个决策函数通常把这个作为输入变量，然后转化为一个二类分类器。通常地，我们用sign(.)函数，就是符号函数，输入变量大于0的作为一类，输入变量小于0的作为另外一类。</li>
</ul>
<h3 id="基于核函数的支持向量机">基于核函数的支持向量机</h3>
<ul>
<li>如上所述，原始的SVM的最优化平面是一个<a href="http://en.wikipedia.org/wiki/Linear_classifier" target="_blank" rel="external">线性分类器</a>。然而，从它在1963年提出的30年后，一些研究者(包括原提出者自己)建议把<a href="http://en.wikipedia.org/wiki/Kernel_trick" target="_blank" rel="external">核技巧</a>应用到那些最大边界超平面来创建一个非线性分类器。结果引起了研究<a href="http://www.kernel-machines.org/" target="_blank" rel="external">“核方法”</a>的一片浪潮，而核方法开始成为一个最有力的而且最受欢迎的分类方法。</li>
<li>不容置疑的是，核技巧是一种非常有力的工具，它提供了一种仅仅依赖于求两个向量的点积的算法来打通了线性和非线性的之间的桥梁。事实上，我们首先把输入数据映射到一个高维空间，然后一个线性的算法就可以在这个空间上操作在原始空间中的非线性的输入数据。</li>
<li>这个“技巧”的厉害之处在于它根本就不用计算映射后的点积；我们所需要做的是找到一个适合的核函数来代替所有的点积(这样便可以简化了计算)。核函数标记特征空间中的一个内积，它通常记为：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/kernel-function-form.png" alt=""><br>(其中Ψ()代表映射函数)。</li>
<li>利用核函数，算法能被带入到高维空间而不需要明确的把输入点映射到这个空间上。这是非常取巧的，特别是当高维的特征空间是无穷多维的，它是不可以计算的时候。正是由于原始的SVM的公式中包含点积运算，它是可以直接应用核技巧的。即使结果分类器在高维特征空间中是个超平面，但在原始空间中它还是非线性的。核技巧的应用同样为不同的视野去进行比较的分类器提供了非常有力的理论支持，例如，生物。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/kernel-transform.png" alt=""></li>
<li>可以很明显的看出，通过核函数(of the form K(z,x) = <z,x> = zTx)，我们又得到了原始线性SVM的相似公式。想了解更详细的关于核技巧的资料和核函数应用的例子，可以参考<a href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" target="_blank" rel="external">previous article about Kernel Discriminant Analysis</a>，或者<a href="http://crsouza.blogspot.com/2010/03/kernel-functions-for-machine-learning.html" target="_blank" rel="external">Kernel Functions for Machine Learning Applications</a>。</z,x></li>
</ul>
<h3 id="多分类的支持向量机">多分类的支持向量机</h3>
<ul>
<li>很不幸的，不像<a href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" target="_blank" rel="external">KDA</a>，支持向量机并没有很自然的推广到多分类的问题。原始的SVM是一个<a href="http://en.wikipedia.org/wiki/Binary_classification" target="_blank" rel="external">二类分类器</a>，它一次只可以在两个分类中进行预测。然而，<a href="http://en.wikipedia.org/wiki/Support_vector_machines#Multiclass_SVM" target="_blank" rel="external">现实问题需要更多的是可以用SVM解决多分类问题</a>，下面我们就来举一个例子。</li>
<li>假设我们有三个分类A,B,C。现在，假设我们只有二类分类器，那么我们怎么把二类分类器去解决一个多分类器的问题呢？其中一个可行的方法就是把我们的多分类问问题拆成多个二类分类器的集合。下面左边的矩阵是泳衣解决三个分类的分类器的二类分类器的所有组合：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/binary-conbination.png" alt=""></li>
<li>然而，注意到上面左边的矩阵中有一些多余的情况。譬如，计算AxA是没有意义的。还有，计算AxB之后再计算BxA是很低效率的，我们计算了AxB后，可以通过取反就得到了BxA。丢弃了多余的选项后，我们只剩下右边的(半透明的，除了AxA,BxB,CxC)矩阵。观察可知，一个n类的分类问题可以拆分成n(n-1)/2个二类分类器的组合组成的小的子集合。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/n-binary.png" alt=""></li>
<li>现在我们得到了3个二类分类的问题，所以，我们需要创建3个SVM来解决每一个子问题。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/3-SVM.png" alt=""></li>
<li>要确定一个分类，我们就看3个SVM当中谁的投票最多。譬如，A在第一个SVM中胜出，而C在其他的两个SVM中都胜出。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/3-SVM-2.png" alt=""></li>
<li>如果我们把胜出次数最多的作为赢家，那么我们应该把它归为C类。这种方法通常称作多分类器中的”一对一”策略。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/table-one-against-one.png" alt=""></li>
<li>另外一种方法是利用“一对多”的策略，把输入放到所有的SVM中，然后选择最高的输出的那个SVM。很不幸的，我们不能保证有最高的输出就是最好的SVM。这个不作本文讨论的范畴。</li>
</ul>
<h2 id="源代码">源代码</h2>
<ul>
<li>基于核方法的支持向量机的代码也是属于<a href="http://accord-framework.net/" target="_blank" rel="external">Accord.NET</a>的一部分，这个框架我做了数年。它是在<a href="http://code.google.com/p/aforge/" target="_blank" rel="external">AForge.NET</a>的顶层建立的,<a href="http://code.google.com/p/aforge/" target="_blank" rel="external">AForge.NET</a>是计算机视觉，机器学习中非常受欢迎的框架，它集合了我过去的研究中的多个主题。目前，它有了<a href="http://crsouza.blogspot.com/2009/09/principal-component-analysis-in-c.html" target="_blank" rel="external">PCA</a>, <a href="http://crsouza.blogspot.com/2010/01/kernel-principal-component-analysis-in.html" target="_blank" rel="external">KPCA</a>, <a href="http://crsouza.blogspot.com/2010/01/linear-discriminant-analysis-in-c.html" target="_blank" rel="external">LDA</a>, <a href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" target="_blank" rel="external">KDA</a>, <a href="http://crsouza.blogspot.com/2010/02/logistic-regression-in-c.html" target="_blank" rel="external">LR</a>, <a href="http://crsouza.blogspot.com/2010/04/partial-least-squares-analysis-and.html" target="_blank" rel="external">PLS</a>, <a href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" target="_blank" rel="external">SVMs</a>, <a href="http://www.codeproject.com/Articles/69647/Hidden-Markov-Models-in-Csharp.aspx" target="_blank" rel="external">HMMs</a>, <a href="http://www.codeproject.com/Articles/55691/Neural-Network-Learning-by-the-Levenberg-Marquardt.aspx" target="_blank" rel="external">LM-ANN</a>和其他的缩写。这个项目在Github上举办，地址是：<a href="https://github.com/accord-net/framework/" target="_blank" rel="external">https://github.com/accord-net/framework/</a>。最小的版本中包含了最小的bug修正，完善和功能加强，新特征等，我强烈推荐大家直接从Github上下载最新的版本库。</li>
</ul>
<h3 id="支持向量机-1">支持向量机</h3>
<ul>
<li>支持向量机类结构如下：(C#和VB实现)<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/svm-class-structure.png" alt=""></li>
<li><a href="http://accord-framework.net/docs/html/T_Accord_MachineLearning_VectorMachines_KernelSupportVectorMachine.htm" target="_blank" rel="external">KernelSupportVectorMachine</a>类继承SupportVectorMachine类，加了kernel方法。MulticlassSupportVectorMachine类集合了一堆实现了“一对一”策略的KernelSupportVectorMachines类来实现多分类器。框架的API在此：<a href="http://accord-framework.net/docs/html/N_Accord_Statistics_Kernels.htm" target="_blank" rel="external">extensive list of machine learning kernel functions to chose from</a>.</li>
</ul>
<h3 id="训练算法">训练算法</h3>
<ul>
<li>训练算法既可以实现分类也可以实现回归。它们是<a href="http://research.microsoft.com/apps/pubs/default.aspx?id=69644" target="_blank" rel="external">Platt的序列最优化(SMO)算法</a>的直接实现。MulticlassSupportVectorLearning类提供了一个回调函数，名字是Configure，它可以被任何的算法选择并进行配置。这个方法并没有强加需要利用哪一种算法，而且还允许用户利用自定义的算法来进行训练。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/svm-class-structure-2.png" alt=""></li>
<li>因为MulticlassSupportVectorLearning算法一次可以训练一堆独立的机器，所以它容易实现并行运算。事实上，这些实现方法在单台机器中可以充分利用剩下的核。</li>
</ul>
<figure class="highlight C#"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment"><span class="xmlDocTag">///</span> <span class="xmlDocTag">&lt;summary&gt;</span></span></div><div class="line"><span class="comment"><span class="xmlDocTag">///</span>   Runs the one-against-one learning algorithm.</span></div><div class="line"><span class="comment"><span class="xmlDocTag">///</span> <span class="xmlDocTag">&lt;/summary&gt;</span></span></div><div class="line"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">Run</span>(<span class="keyword">bool</span> computeError)</div><div class="line">{</div><div class="line">    <span class="comment">// For each class i</span></div><div class="line">    AForge.Parallel.For(<span class="number">0</span>, msvm.Classes, <span class="keyword">delegate</span>(<span class="keyword">int</span> i)</div><div class="line">    {</div><div class="line">        <span class="comment">// For each class j</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++)</div><div class="line">        {</div><div class="line">            <span class="comment">// Retrieve the associated machine</span></div><div class="line">            <span class="keyword">var</span> machine = msvm[i,j];</div><div class="line"></div><div class="line">            <span class="comment">// Retrieve the associated classes</span></div><div class="line">            <span class="keyword">int</span>[] idx = outputs.Find(x =&gt; x == i || x == j);</div><div class="line">            <span class="keyword">double</span>[][] subInputs = inputs.Submatrix(idx);</div><div class="line">            <span class="keyword">int</span>[] subOutputs = outputs.Submatrix(idx);</div><div class="line">   </div><div class="line">            <span class="comment">// Transform in a two-class problem</span></div><div class="line">            subOutputs.ApplyInPlace(x =&gt; x = (x == i) ? -<span class="number">1</span> : <span class="number">1</span>);</div><div class="line">            </div><div class="line">            <span class="comment">// Train the machine on the two-class problem.</span></div><div class="line">            configure(machine, subInputs, subOutputs).Run(<span class="keyword">false</span>);</div><div class="line">        }</div><div class="line">    });</div><div class="line">}</div></pre></td></tr></table></figure>


<ul>
<li>上面的代码利用了<a href="http://www.codeproject.com/KB/cs/aforge_parallel.aspx" target="_blank" rel="external">AForge.NET Parallel</a>的构造器和<a href="http://crsouza.blogspot.com/2010/08/matrix-manipulation-using-accordnet.html" target="_blank" rel="external">Accord.NET matrix extensions</a>。我决定不用最新加的 .NET 4.0 Parallel Extensions,所以这个框架还是兼容.NET 3.5 applications的应用的。</li>
</ul>
<h2 id="数字识别">数字识别</h2>
<h3 id="UCI的光学数字数据集">UCI的光学数字数据集</h3>
<ul>
<li>如果你读了上一篇文章<a href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" target="_blank" rel="external">Kernel Discriminant Analysis for Handwritten Digit Recognition</a>，那么请跳过本小节。本小节只是对UCI机器学习的光学数字数据库的介绍。</li>
<li><a href="http://archive.ics.uci.edu/ml/" target="_blank" rel="external">UCI机器学习库</a>是一个被机器学习社区用于做机器学习算法实践分析的数据库，域理论，数据生成器的集合。其中一个就是<a href="http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits" target="_blank" rel="external">光学识别的手写数字数据集</a>，又叫Optdigits Dataset.</li>
<li>原始的光学数字数据是一个个32x32的矩阵。它们提供经过预处理的数字形式，数字被分成非重叠的4x4块，每一块上像素都合计了。这就生成了8x8输入矩阵，每一个元素都是0到16的整数。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/digit.png" alt=""></li>
</ul>
<h3 id="基于多分类的SVM的数字分类器">基于多分类的SVM的数字分类器</h3>
<ul>
<li>核方法引起了很大的兴趣，因为它可以应用到那些需要进行预处理的(例如，数据降维)数据的问题上和被模型化的数据结构的扩展知识上。即使我们对数据知之甚少，核方法的直接应用往往得到令人感兴趣的结果。利用核方法实现最佳化是一个非常难的任务，因为我们用无穷多的核函数可供选择，而每个核函数也有无穷多的参数可供调整。</li>
<li>下面的代码向我们展示了基于核函数的支持向量机是怎么实现的。输入的是一个1024的全向量。这个对神经网络来说是不切实际的，例如，通常的核方法处理高维数的问题是没问题的，因为它不会遭受维数灾难。</li>
</ul>
<figure class="highlight C#"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Extract inputs and outputs</span></div><div class="line"><span class="keyword">int</span> samples = <span class="number">500</span>;</div><div class="line"><span class="keyword">double</span>[][] input = <span class="keyword">new</span> <span class="keyword">double</span>[samples][];</div><div class="line"><span class="keyword">int</span>[] output = <span class="keyword">new</span> <span class="keyword">int</span>[samples];</div><div class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; samples; i++)</div><div class="line">{</div><div class="line">   ...</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Create the chosen Kernel with given parameters</span></div><div class="line">IKernel kernel = <span class="keyword">new</span> Polynomial((<span class="keyword">int</span>)numDegree.Value, (<span class="keyword">double</span>)numConstant.Value);</div><div class="line"></div><div class="line"><span class="comment">// Create the Multi-class Support Vector Machine using the selected Kernel</span></div><div class="line">ksvm = <span class="keyword">new</span> MulticlassSupportVectorMachine(<span class="number">1024</span>, kernel, <span class="number">10</span>);</div><div class="line"></div><div class="line"><span class="comment">// Create the learning algorithm using the machine and the training data</span></div><div class="line"><span class="keyword">var</span> ml = <span class="keyword">new</span> MulticlassSupportVectorLearning(ksvm, input, output);</div><div class="line"></div><div class="line"><span class="comment">// Extract training parameters from the interface</span></div><div class="line"><span class="keyword">double</span> complexity = (<span class="keyword">double</span>)numComplexity.Value;</div><div class="line"><span class="keyword">double</span> epsilon = (<span class="keyword">double</span>)numEpsilon.Value;</div><div class="line"><span class="keyword">double</span> tolerance = (<span class="keyword">double</span>)numTolerance.Value;</div><div class="line"></div><div class="line"><span class="comment">// Configure the learning algorithm</span></div><div class="line">ml.Configure = <span class="keyword">delegate</span>(KernelSupportVectorMachine svm, </div><div class="line">                        <span class="keyword">double</span>[][] cinput, <span class="keyword">int</span>[] coutput)</div><div class="line">{</div><div class="line">    <span class="keyword">var</span> smo = <span class="keyword">new</span> SequentialMinimalOptimization(svm, cinput, coutput);</div><div class="line">    smo.Complexity = complexity;</div><div class="line">    smo.Epsilon    = epsilon;</div><div class="line">    smo.Tolerance  = tolerance;</div><div class="line">    <span class="keyword">return</span> smo;</div><div class="line">};</div><div class="line"></div><div class="line"><span class="comment">// Train the machines. It should take a while.</span></div><div class="line"><span class="keyword">double</span> error = ml.Run();</div></pre></td></tr></table></figure>

<h2 id="应用例子">应用例子</h2>
<h3 id="学习">学习</h3>
<ul>
<li>样例应用附带源代码，它实现了基于核函数的多分类支持向量机的手写数字识别。下载了应用后，打开并点击菜单，然后选择”Open”。它就会载入数据。</li>
<li>要开始训练数据，点击“Start training”。利用默认设置，应该不会太长时间。因为代码是用了并行运算，核数越多，训练越快。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-1.png" alt=""></li>
<li>训练完成后，点击“Classify”开始分类测试数据集。利用默认值，它应该可以得到95%的正确率，大概是500个数据中有475个分类正确。识别率的大小会随着每次训练的不同而有小小的波动。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-2.png" alt=""></li>
<li>相同的集合和相同的训练和测试样本已经在上一篇中的基于核方法的判别分析方法中使用。而SVM却得到更高的运行效率和更少的内存，更多的样本数可能得到更高的正确率。</li>
<li>训练后，创建的SVM可以在“Machine”这个tab中看到。每次的SVM的支持向量和临界值可以在第一个数据格视图中通过选择一个数据入口而看到。向量越暗，在决策过程中它的权值就越大。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-3.png" alt=""></li>
</ul>
<h3 id="结果">结果</h3>
<ul>
<li>即使识别率刚刚超过3%，但是识别的正确率已经比KDA大大的提升了。点击“Classification”tab，我们可以手动地为用户手写的数字测试多分类支持向量机。<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-4.png" alt=""></li>
<li>我们看到SVM方法产生了更强壮的结果，即使手写很差的数字也能识别正确：<br><img src="/img/paperBlog/CodeProject-Handwriting-kernelSVM/app-5.png" alt=""></li>
<li>最后，有一个视频演示：   </li>
</ul>
<iframe height="498" width="610" src="http://player.youku.com/embed/XODYzNjk3NzMy" frameborder="0" allowfullscreen></iframe>

<h2 id="总结">总结</h2>
<ul>
<li>在本文中，我们详细叙述和探索了基于核方法的SVM来解决手写数字识别的问题，并且可以得到更好的结果。</li>
<li>SVM适合小样本的数据训练。</li>
</ul>
<h2 id="继续阅读">继续阅读</h2>
<ul>
<li><a href="http://www.codeproject.com/KB/recipes/handwriting-kda.aspx" target="_blank" rel="external">Handwriting Recognition using Kernel Discriminant Analysis</a></li>
<li><a href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" target="_blank" rel="external">Kernel Functions for Machine Learning Applications</a></li>
<li><a href="http://crsouza.blogspot.com/2010/04/kernel-support-vector-machines-for.html" target="_blank" rel="external">Kernel Support Vector Machines (SVM)</a></li>
<li><a href="http://crsouza.blogspot.com/2009/09/principal-component-analysis-in-c.html" target="_blank" rel="external">Principal Component Analysis (PCA)</a></li>
<li><a href="http://crsouza.blogspot.com/2010/01/kernel-principal-component-analysis-in.html" target="_blank" rel="external">Kernel Principal Component Analysis (KPCA)</a></li>
<li><a href="http://crsouza.blogspot.com/2010/01/linear-discriminant-analysis-in-c.html" target="_blank" rel="external">Linear Discriminant Analysis (LDA)</a></li>
<li><a href="http://crsouza.blogspot.com/2010/01/kernel-discriminant-analysis-in-c.html" target="_blank" rel="external">Non-Linear Discriminant Analysis with Kernels (KDA)</a></li>
<li><a href="http://crsouza.blogspot.com/2010/02/logistic-regression-in-c.html" target="_blank" rel="external">Logistic Regression Analysis</a></li>
</ul>
<h2 id="参考">参考</h2>
<ul>
<li>Wikipedia contributors,<a href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization" target="_blank" rel="external">“Sequential Minimal Optimization”</a>, Wikipedia, The Free Encyclopedia,<a href="http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization" target="_blank" rel="external">http://en.wikipedia.org/wiki/Sequential_Minimal_Optimization</a> (accessed April 24, 2010).</li>
<li>Wikipedia contributors, <a href="http://en.wikipedia.org/wiki/Support_vector_machine" target="_blank" rel="external">“Support Vector Machine”</a>, Wikipedia, The Free Encyclopedia,<a href="http://en.wikipedia.org/wiki/Support_vector_machine" target="_blank" rel="external">http://en.wikipedia.org/wiki/Support_vector_machine</a>,(accessed April 24, 2010).</li>
<li>John C. Platt,<a href="http://research.microsoft.com/en-us/um/people/jplatt/smoTR.pdf" target="_blank" rel="external">Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines</a> , Microsoft Research, 1998.</li>
<li>J. P. Lewis,<a href="http://www.idiom.com/~zilla/Work/Notes/svmtutorial.pdf" target="_blank" rel="external">A Short SVM (Support Vector Machine) Tutorial.</a>,CGIT Lab / IMSC, University of Southern California.</li>
<li>A. J. Smola and B. Scholkopf,<a href="http://www.kernel-machines.org/publications/SmoSch98c" target="_blank" rel="external">A Tutorial on Support Vector Regression.</a>,NeuroCOLT2 Technical Report Series, 1998.</li>
<li>S. K. Shevade et al.<a href="http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz" target="_blank" rel="external">Improvements to SMO Algorithm for SVM Regression</a>,1999.</li>
<li>G. W. Flake, S. Lawrence<a href="http://www.keerthis.com/smoreg_ieee_shevade_00.pdf" target="_blank" rel="external">Efficient SVM Regression Training with SMO</a></li>
<li>A. Asuncion &amp; D.J. Newman,<a href="http://archive.ics.uci.edu/ml/index.html" target="_blank" rel="external">UCI Machine Learning Repository.</a>Irvine, CA: University of California, School of Information and Computer Science (2007).</li>
<li>Andrew Kirillov,<a href="http://aforgenet.com/framework" target="_blank" rel="external">The AForge.NET Framework</a>.The AForge.NET Computer Vision, Artificial Intelligence and Robotics Website, 2010.</li>
<li>C. R. Souza, <a href="http://crsouza.blogspot.com/2010/03/kernel-functions-for-machine-learning.html" target="_blank" rel="external">Kernel Functions for Machine Learning Applications.</a> 17 Mar. 2010. Web.</li>
</ul>
<h1 id="后记">后记</h1>
<ul>
<li>翻译这篇文章后，除了对翻译的难度有了更深一层的认知之后，本次只要是对SVM进行多分类问题的解决有了更深的认识。SVM本来是一个二类分类器，那么要解决多分类问题，应该要什么思路呢？就是用二类分类器进行组合，然后通过“一对一”策略来解决多分类分类器。</li>
</ul>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/毕业设计系列/">毕业设计系列</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/手写数字识别-Kernel-Support-Vector-Machine/">手写数字识别 Kernel Support Vector Machine</a>
  </div>

</div>


<div class="article-share" id="share">

<div class="share-jiathis">
  
<div class="jiathis_style_24x24">
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_googleplus"></a>
	<a class="jiathis_button_douban"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
    var jiathis_config={
    data_track_clickback:true,
    sm:"copy,renren,cqq",
    pic:"",
    summary:"",
     ralateuid:{"tsina":"2155417625"},hideMore:false}
    
  </script> 
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js?uid=
" charset="utf-8"></script>      

 </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2015/01/04/【基础】常用的机器学习-数据挖掘知识点/" title="【基础】常用的机器学习&amp;数据挖掘知识点">
  <strong>上一篇：</strong><br/>
  <span>
  【基础】常用的机器学习&amp;数据挖掘知识点</span>
</a>
</div>


<div class="next">
<a href="/2015/01/01/最小二乘法论文翻译-毕设系列/"  title="最小二乘法论文翻译-毕设系列">
 <strong>下一篇：</strong><br/> 
 <span>最小二乘法论文翻译-毕设系列
</span>
</a>
</div>

</nav>

	
<section class="comment">
	<div class="ds-thread"></div>
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"tim4chan"};
		(function() {
			var ds = document.createElement('script');
			ds.type = 'text/javascript';ds.async = true;
			ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
			ds.charset = 'UTF-8';
			(document.getElementsByTagName('head')[0] 
			 || document.getElementsByTagName('body')[0]).appendChild(ds);
		})();
		</script>
</section>


</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#写在前面的话"><span class="toc-number">1.</span> <span class="toc-text">写在前面的话</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#博文正文"><span class="toc-number">2.</span> <span class="toc-text">博文正文</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">2.1.</span> <span class="toc-text">简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#支持向量机"><span class="toc-number">2.1.1.</span> <span class="toc-text">支持向量机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基于核函数的支持向量机"><span class="toc-number">2.1.2.</span> <span class="toc-text">基于核函数的支持向量机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多分类的支持向量机"><span class="toc-number">2.1.3.</span> <span class="toc-text">多分类的支持向量机</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#源代码"><span class="toc-number">2.2.</span> <span class="toc-text">源代码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#支持向量机-1"><span class="toc-number">2.2.1.</span> <span class="toc-text">支持向量机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#训练算法"><span class="toc-number">2.2.2.</span> <span class="toc-text">训练算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数字识别"><span class="toc-number">2.3.</span> <span class="toc-text">数字识别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#UCI的光学数字数据集"><span class="toc-number">2.3.1.</span> <span class="toc-text">UCI的光学数字数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基于多分类的SVM的数字分类器"><span class="toc-number">2.3.2.</span> <span class="toc-text">基于多分类的SVM的数字分类器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#应用例子"><span class="toc-number">2.4.</span> <span class="toc-text">应用例子</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#学习"><span class="toc-number">2.4.1.</span> <span class="toc-text">学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结果"><span class="toc-number">2.4.2.</span> <span class="toc-text">结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">2.5.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#继续阅读"><span class="toc-number">2.6.</span> <span class="toc-text">继续阅读</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-number">2.7.</span> <span class="toc-text">参考</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#后记"><span class="toc-number">3.</span> <span class="toc-text">后记</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">Categories</p>
		<ul>
		
			<li><a href="/categories/Django/" title="Django">Django<sup>1</sup></a></li>
		
			<li><a href="/categories/JSP-Review/" title="JSP_Review">JSP_Review<sup>10</sup></a></li>
		
			<li><a href="/categories/R-Tutorial/" title="R Tutorial">R Tutorial<sup>4</sup></a></li>
		
			<li><a href="/categories/probability-theory-basic-conception/" title="probability-theory-basic-conception">probability-theory-basic-conception<sup>1</sup></a></li>
		
			<li><a href="/categories/医学图像处理/" title="医学图像处理">医学图像处理<sup>2</sup></a></li>
		
			<li><a href="/categories/原型设计/" title="原型设计">原型设计<sup>1</sup></a></li>
		
			<li><a href="/categories/备忘/" title="备忘">备忘<sup>1</sup></a></li>
		
			<li><a href="/categories/技术开发/" title="技术开发">技术开发<sup>1</sup></a></li>
		
			<li><a href="/categories/数据挖掘与R语言-案例学习/" title="数据挖掘与R语言-案例学习">数据挖掘与R语言-案例学习<sup>4</sup></a></li>
		
			<li><a href="/categories/数据挖掘算法总结/" title="数据挖掘算法总结">数据挖掘算法总结<sup>3</sup></a></li>
		
			<li><a href="/categories/机器学习/" title="机器学习">机器学习<sup>2</sup></a></li>
		
			<li><a href="/categories/概率论笔记/" title="概率论笔记">概率论笔记<sup>2</sup></a></li>
		
			<li><a href="/categories/毕业设计系列/" title="毕业设计系列">毕业设计系列<sup>8</sup></a></li>
		
			<li><a href="/categories/毕设系列/" title="毕设系列">毕设系列<sup>1</sup></a></li>
		
			<li><a href="/categories/面试分享/" title="面试分享">面试分享<sup>2</sup></a></li>
		
			<li><a href="/categories/黑马程序员/" title="黑马程序员">黑马程序员<sup>2</sup></a></li>
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			<li><a href="/tags/JSP-网页开发/" title="JSP 网页开发">JSP 网页开发<sup>10</sup></a></li>
		
			<li><a href="/tags/数据挖掘/" title="数据挖掘">数据挖掘<sup>5</sup></a></li>
		
			<li><a href="/tags/R-basics/" title="R basics">R basics<sup>4</sup></a></li>
		
			<li><a href="/tags/SVM入门/" title="SVM入门">SVM入门<sup>2</sup></a></li>
		
			<li><a href="/tags/概率论/" title="概率论">概率论<sup>2</sup></a></li>
		
			<li><a href="/tags/面试算法/" title="面试算法">面试算法<sup>1</sup></a></li>
		
			<li><a href="/tags/最小二乘法-论文翻译/" title="最小二乘法 论文翻译">最小二乘法 论文翻译<sup>1</sup></a></li>
		
			<li><a href="/tags/最小二乘法/" title="最小二乘法">最小二乘法<sup>1</sup></a></li>
		
			<li><a href="/tags/FP-growth-tree/" title="FP-growth-tree">FP-growth-tree<sup>1</sup></a></li>
		
			<li><a href="/tags/Aprior-Algorithm/" title="Aprior Algorithm">Aprior Algorithm<sup>1</sup></a></li>
		
			<li><a href="/tags/手写数字-SVM/" title="手写数字 SVM">手写数字 SVM<sup>1</sup></a></li>
		
			<li><a href="/tags/手写数字识别-Kernel-Support-Vector-Machine/" title="手写数字识别 Kernel Support Vector Machine">手写数字识别 Kernel Support Vector Machine<sup>1</sup></a></li>
		
			<li><a href="/tags/感知机/" title="感知机">感知机<sup>1</sup></a></li>
		
			<li><a href="/tags/机器学习入门基础/" title="机器学习入门基础">机器学习入门基础<sup>1</sup></a></li>
		
			<li><a href="/tags/二值化/" title="二值化">二值化<sup>1</sup></a></li>
		
			<li><a href="/tags/机器学习基础/" title="机器学习基础">机器学习基础<sup>1</sup></a></li>
		
			<li><a href="/tags/梯度下降法/" title="梯度下降法">梯度下降法<sup>1</sup></a></li>
		
			<li><a href="/tags/概率论基本概念/" title="概率论基本概念">概率论基本概念<sup>1</sup></a></li>
		
			<li><a href="/tags/有价值的博客记录/" title="有价值的博客记录">有价值的博客记录<sup>1</sup></a></li>
		
			<li><a href="/tags/原型设计/" title="原型设计">原型设计<sup>1</sup></a></li>
		
		</ul>
</div>


  
  <div class="tagcloudlist">
    <p class="asidetitle">Tag Cloud</p>
    <div class="tagcloudlist clearfix">
       <a href="/tags/Aprior-Algorithm/" style="font-size: 10.00px;">Aprior Algorithm</a><a href="/tags/Django-Models/" style="font-size: 10.00px;">Django-Models</a><a href="/tags/FP-growth-tree/" style="font-size: 10.00px;">FP-growth-tree</a><a href="/tags/JSP-网页开发/" style="font-size: 20.00px;">JSP 网页开发</a><a href="/tags/R-basics/" style="font-size: 15.00px;">R basics</a><a href="/tags/SVM/" style="font-size: 10.00px;">SVM</a><a href="/tags/SVM入门/" style="font-size: 12.50px;">SVM入门</a><a href="/tags/linux-C/" style="font-size: 10.00px;">linux C</a><a href="/tags/二值化/" style="font-size: 10.00px;">二值化</a><a href="/tags/单例设计模式/" style="font-size: 10.00px;">单例设计模式</a><a href="/tags/原型设计/" style="font-size: 10.00px;">原型设计</a><a href="/tags/多线程/" style="font-size: 10.00px;">多线程</a><a href="/tags/字符串操作/" style="font-size: 10.00px;">字符串操作</a><a href="/tags/感知机/" style="font-size: 10.00px;">感知机</a><a href="/tags/手写数字-SVM/" style="font-size: 10.00px;">手写数字 SVM</a><a href="/tags/手写数字识别-Kernel-Support-Vector-Machine/" style="font-size: 10.00px;">手写数字识别 Kernel Support Vector Machine</a><a href="/tags/数据挖掘/" style="font-size: 17.50px;">数据挖掘</a><a href="/tags/最小二乘法/" style="font-size: 10.00px;">最小二乘法</a><a href="/tags/最小二乘法-论文翻译/" style="font-size: 10.00px;">最小二乘法 论文翻译</a><a href="/tags/有价值的博客记录/" style="font-size: 10.00px;">有价值的博客记录</a><a href="/tags/机器学习入门基础/" style="font-size: 10.00px;">机器学习入门基础</a><a href="/tags/机器学习基础/" style="font-size: 10.00px;">机器学习基础</a><a href="/tags/梯度下降法/" style="font-size: 10.00px;">梯度下降法</a><a href="/tags/概率论/" style="font-size: 12.50px;">概率论</a><a href="/tags/概率论基本概念/" style="font-size: 10.00px;">概率论基本概念</a><a href="/tags/正则表达式/" style="font-size: 10.00px;">正则表达式</a><a href="/tags/灰度直方图/" style="font-size: 10.00px;">灰度直方图</a><a href="/tags/面试算法/" style="font-size: 10.00px;">面试算法</a>
    </div>
  </div>


  <div class="weiboshow">
  <p class="asidetitle">Weibo</p>
<iframe width="100%" height="300" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=300&fansRow=2&ptype=1&speed=300&skin=1&isTitle=1&noborder=1&isWeibo=1&isFans=0&uid=2155417625&verifier=9f994c23&dpc=1"></iframe>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
	  <li><a href="http://zjdian.com/" target="_blank" title="zjdian">中继点</li>
      <li><a href="http://ripeconan.com/" target="_blank" title="ripeconan">Ripeconan</a></li>
      <li><a href="http://hexo.io" target="_blank" title="Hexo">Hexo</a></li>
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello, I&#39;m Tim Chan. <br/>
			Welcome to my personal blog.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/2155417625" target="_blank" class="icon-weibo" title="weibo"></a>
		
		
		<a href="https://github.com/chenyuqing" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		<a href="https://www.douban.com/people/motoleiusre" target="_blank" class="icon-douban" title="豆瓣"></a>
		
		
		
		<a href="mailto:motoleisure@gmail.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Pacman">Jacman</a> © 2015 
		
		<a href="http://tim4chan.com/about" target="_blank" title="Tim Chan">Tim Chan</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>




<script type="text/javascript">
  var duoshuoQuery = {short_name:"乐果404"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 







<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>





<div id="totop">
<a title="Back to Top"><img src="/img/scrollup.png"/></a>
</div>

<script src="/js/totop.js"></script>




  </body>
</html>


<a href="https://github.com/chenyuqing/chenyuqing.github.io"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/652c5b9acfaddf3a9c326fa6bde407b87f7be0f4/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6f72616e67655f6666373630302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a>