
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>【基础】常用的机器学习&amp;数据挖掘知识点 | Tim Chan&#39;s Blog!</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Tim Chan">
    
    <meta name="description" content="说明


转自：36大数据
本文总结了机器学习入门的基础知识的标题。相当于给我们入门者一个学习的架构。

Basis(基础)

MSE(Mean Square Error (均方误差)
LMS(LeastMean Square (最小均方)
LSM(Least Square Methods (最小二">
    
    
    
    
    <link rel="alternative" href="/atom.xml" title="Tim Chan&#39;s Blog!" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">

</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Tim Chan&#39;s Blog!" title="Tim Chan&#39;s Blog!"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Tim Chan&#39;s Blog!">Tim Chan&#39;s Blog!</a></h1>
				<h2 class="blog-motto">记录生活点滴！</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于我</a></li>
					
						<li><a href="https://pomotodo.com/app/">ToDo</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:tim4chan.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/01/04/【基础】常用的机器学习-数据挖掘知识点/" title="【基础】常用的机器学习&amp;数据挖掘知识点" itemprop="url">【基础】常用的机器学习&amp;数据挖掘知识点</a>
  </h1>
  <p class="article-author">By
       
		<a href="http://tim4chan.com/about" title="Tim Chan" target="_blank" itemprop="author">Tim Chan</a>
		
  <p class="article-time">
    <time datetime="2015-01-04T11:04:41.000Z" itemprop="datePublished"> Published Jan 4 2015</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#说明"><span class="toc-number">1.</span> <span class="toc-text">说明</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Basis(基础)"><span class="toc-number">1.1.</span> <span class="toc-text">Basis(基础)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Common_Distribution(常见分布)"><span class="toc-number">1.2.</span> <span class="toc-text">Common Distribution(常见分布)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Discrete_Distribution(离散型分布)"><span class="toc-number">1.2.1.</span> <span class="toc-text">Discrete Distribution(离散型分布)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Continuous_Distribution_(连续型分布)"><span class="toc-number">1.2.2.</span> <span class="toc-text">Continuous Distribution (连续型分布)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Three_Sampling_Distribution(三大抽样分布)"><span class="toc-number">1.2.3.</span> <span class="toc-text">Three Sampling Distribution(三大抽样分布)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data_Pre-processing(数据预处理)"><span class="toc-number">1.3.</span> <span class="toc-text">Data Pre-processing(数据预处理)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sampling(采样)"><span class="toc-number">1.4.</span> <span class="toc-text">Sampling(采样)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Clustering(聚类)"><span class="toc-number">1.5.</span> <span class="toc-text">Clustering(聚类)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Classification&Regression(分类&回归)"><span class="toc-number">1.6.</span> <span class="toc-text">Classification&Regression(分类&回归)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Effectiveness_Evaluation(分类效果评估)"><span class="toc-number">1.7.</span> <span class="toc-text">Effectiveness Evaluation(分类效果评估)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PGM(Probabilistic_Graphical_Models概率图模型)"><span class="toc-number">1.8.</span> <span class="toc-text">PGM(Probabilistic Graphical Models概率图模型)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NN(Neural_Network神经网络)"><span class="toc-number">1.9.</span> <span class="toc-text">NN(Neural Network神经网络)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep_Learning(深度学习)"><span class="toc-number">1.10.</span> <span class="toc-text">Deep Learning(深度学习)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DimensionalityReduction(降维)"><span class="toc-number">1.11.</span> <span class="toc-text">DimensionalityReduction(降维)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Text_Mining(文本挖掘)"><span class="toc-number">1.12.</span> <span class="toc-text">Text Mining(文本挖掘)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Association_Mining(关联挖掘)"><span class="toc-number">1.13.</span> <span class="toc-text">Association Mining(关联挖掘)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recommendation_Engine(推荐引擎)"><span class="toc-number">1.14.</span> <span class="toc-text">Recommendation Engine(推荐引擎)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Similarity_Measure&Distance_Measure(相似性与距离度量)："><span class="toc-number">1.15.</span> <span class="toc-text">Similarity Measure&Distance Measure(相似性与距离度量)：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Optimization(最优化)"><span class="toc-number">1.16.</span> <span class="toc-text">Optimization(最优化)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Non-constrainedOptimization(无约束优化)"><span class="toc-number">1.16.1.</span> <span class="toc-text">Non-constrainedOptimization(无约束优化)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ConstrainedOptimization(有约束优化)"><span class="toc-number">1.16.2.</span> <span class="toc-text">ConstrainedOptimization(有约束优化)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Feature_Selection(特征选择算法)"><span class="toc-number">1.17.</span> <span class="toc-text">Feature Selection(特征选择算法)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Outlier_Detection(异常点检测算法)"><span class="toc-number">1.18.</span> <span class="toc-text">Outlier Detection(异常点检测算法)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Learning_to_Rank(基于学习的排序)"><span class="toc-number">1.19.</span> <span class="toc-text">Learning to Rank(基于学习的排序)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tool(工具)"><span class="toc-number">1.20.</span> <span class="toc-text">Tool(工具)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#End"><span class="toc-number">2.</span> <span class="toc-text">End</span></a></li></ol>
		
		</div>
		
		<h1 id="说明">说明</h1>
<ul>
<li><img src="/img/repost/ml-basic.png" alt=""></li>
<li>转自：<a href="http://www.36dsj.com/archives/20135#rd" target="_blank" rel="external">36大数据</a></li>
<li>本文总结了机器学习入门的基础知识的<font color="red"><strong>标题</strong></font>。相当于给我们入门者一个学习的架构。</li>
</ul>
<h2 id="Basis(基础)">Basis(基础)</h2>
<ul>
<li>MSE(Mean Square Error (均方误差)</li>
<li>LMS(LeastMean Square (最小均方)</li>
<li>LSM(Least Square Methods (最小二乘法)</li>
<li>MLE(MaximumLikelihood Estimation (最大似然估计)</li>
<li>QP(Quadratic Programming (二次规划) </li>
<li>CP(Conditional Probability (条件概率)</li>
<li>JP(Joint Probability (联合概率)</li>
<li>MP(Marginal Probability (边缘概率)</li>
<li>Bayesian Formula (贝叶斯公式)</li>
<li>L1 /L2Regularization (L1/L2正则，以及更多的，现在比较火的L2.5正则等)</li>
<li>GD (GradientDescent 梯度下降)</li>
<li>SGD (Stochastic Gradient Descent 随机梯度下降)</li>
<li>Eigenvalue (特征值)</li>
<li>Eigenvector (特征向量)</li>
<li>QR-decomposition (QR分解)</li>
<li>Quantile (分位数)</li>
<li>Covariance (协方差矩阵)</li>
</ul>
<h2 id="Common_Distribution(常见分布)">Common Distribution(常见分布)</h2>
<h3 id="Discrete_Distribution(离散型分布)">Discrete Distribution(离散型分布)</h3>
<ul>
<li>BernoulliDistribution/Binomial(贝努利分布/二项分布)</li>
<li>Negative BinomialDistribution(负二项分布)</li>
<li>MultinomialDistribution(多项式分布)</li>
<li>Geometric Distribution(几何分布)</li>
<li>HypergeometricDistribution(超几何分布)</li>
<li>Poisson Distribution (泊松分布)</li>
</ul>
<h3 id="Continuous_Distribution_(连续型分布)">Continuous Distribution (连续型分布)</h3>
<ul>
<li>UniformDistribution(均匀分布)</li>
<li>Normal Distribution /Guassian Distribution(正态分布/高斯分布)</li>
<li>ExponentialDistribution(指数分布)</li>
<li>Lognormal Distribution(对数正态分布)</li>
<li>GammaDistribution(Gamma分布)</li>
<li>Beta Distribution(Beta分布)</li>
<li>Dirichlet Distribution(狄利克雷分布)</li>
<li>Rayleigh Distribution(瑞利分布)</li>
<li>Cauchy Distribution(柯西分布)</li>
<li>Weibull Distribution (韦伯分布)</li>
</ul>
<h3 id="Three_Sampling_Distribution(三大抽样分布)">Three Sampling Distribution(三大抽样分布)</h3>
<ul>
<li>Chi-squareDistribution(卡方分布)</li>
<li>t-distribution(t-分布)</li>
<li>F-distribution(F-分布)</li>
</ul>
<h2 id="Data_Pre-processing(数据预处理)">Data Pre-processing(数据预处理)</h2>
<ul>
<li>Missing Value Imputation(缺失值填充)</li>
<li>Discretization(离散化)</li>
<li>Mapping(映射)</li>
<li>Normalization(归一化/标准化)</li>
</ul>
<h2 id="Sampling(采样)">Sampling(采样)</h2>
<ul>
<li>Simple Random Sampling(简单随机采样)</li>
<li>OfflineSampling(离线等可能K采样)</li>
<li>Online Sampling(在线等可能K采样)</li>
<li>Ratio-based Sampling(等比例随机采样)</li>
<li>Acceptance-RejectionSampling(接受-拒绝采样)</li>
<li>Importance Sampling(重要性采样)</li>
<li>MCMC(MarkovChain Monte Carlo 马尔科夫蒙特卡罗采样算法：Metropolis-Hasting&amp; Gibbs)</li>
</ul>
<h2 id="Clustering(聚类)">Clustering(聚类)</h2>
<ul>
<li>K-Means</li>
<li>K-Mediods</li>
<li>二分K-Means</li>
<li>FK-Means</li>
<li>Canopy</li>
<li>Spectral-KMeans(谱聚类)</li>
<li>GMM-EM(混合高斯模型-期望最大化算法解决)</li>
<li>K-Pototypes</li>
<li>CLARANS(基于划分)</li>
<li>BIRCH(基于层次)</li>
<li>CURE(基于层次)</li>
<li>DBSCAN(基于密度)</li>
<li>CLIQUE(基于密度和基于网格)</li>
</ul>
<h2 id="Classification&amp;Regression(分类&amp;回归)">Classification&amp;Regression(分类&amp;回归)</h2>
<ul>
<li>LR(Linear Regression 线性回归)</li>
<li>LR(LogisticRegression逻辑回归)</li>
<li>SR(Softmax Regression 多分类逻辑回归)</li>
<li>GLM(GeneralizedLinear Model 广义线性模型)</li>
<li>RR(Ridge Regression 岭回归/L2正则最小二乘回归)</li>
<li>LASSO(Least Absolute Shrinkage andSelectionator Operator L1正则最小二乘回归)</li>
<li>RF(随机森林)</li>
<li>DT(DecisionTree决策树)</li>
<li>GBDT(Gradient BoostingDecision Tree 梯度下降决策树)</li>
<li>CART(ClassificationAnd Regression Tree 分类回归树)</li>
<li>KNN(K-Nearest Neighbor K近邻)</li>
<li>SVM(Support VectorMachine)</li>
<li>KF(KernelFunction 核函数)</li>
<li>PolynomialKernel Function 多项式核函数</li>
<li>Guassian KernelFunction 高斯核函数</li>
<li>Radial BasisFunction RBF径向基函数</li>
<li>String KernelFunction (字符串核函数)</li>
<li>NB(Naive Bayes 朴素贝叶斯)</li>
<li>BN(Bayesian Network/Bayesian Belief Network/ Belief Network 贝叶斯网络/贝叶斯信度网络/信念网络)</li>
<li>LDA(Linear Discriminant Analysis/FisherLinear Discriminant 线性判别分析/Fisher线性判别)</li>
<li>EL(Ensemble Learning集成学习Boosting，Bagging，Stacking)</li>
<li>AdaBoost(Adaptive Boosting 自适应增强)</li>
<li>MEM(MaximumEntropy Model最大熵模型)</li>
</ul>
<h2 id="Effectiveness_Evaluation(分类效果评估)">Effectiveness Evaluation(分类效果评估)</h2>
<ul>
<li>Confusion Matrix(混淆矩阵)</li>
<li>Precision(精确度)</li>
<li>Recall(召回率)</li>
<li>Accuracy(准确率)</li>
<li>F-score(F得分)</li>
<li>ROC Curve(ROC曲线)</li>
<li>AUC(AUC面积)</li>
<li>LiftCurve(Lift曲线) </li>
<li>KS Curve(KS曲线)</li>
</ul>
<h2 id="PGM(Probabilistic_Graphical_Models概率图模型)">PGM(Probabilistic Graphical Models概率图模型)</h2>
<ul>
<li>BN(Bayesian Network/Bayesian Belief Network/ BeliefNetwork 贝叶斯网络/贝叶斯信度网络/信念网络)</li>
<li>MC(Markov Chain 马尔科夫链)</li>
<li>HMM(HiddenMarkov Model 马尔科夫模型)</li>
<li>MEMM(Maximum Entropy Markov Model 最大熵马尔科夫模型)</li>
<li>CRF(ConditionalRandom Field 条件随机场)</li>
<li>MRF(MarkovRandom Field 马尔科夫随机场)</li>
</ul>
<h2 id="NN(Neural_Network神经网络)">NN(Neural Network神经网络)</h2>
<ul>
<li>ANN(Artificial Neural Network 人工神经网络)</li>
<li>BP(Error BackPropagation 误差反向传播)</li>
</ul>
<h2 id="Deep_Learning(深度学习)">Deep Learning(深度学习)</h2>
<ul>
<li>Auto-encoder(自动编码器)</li>
<li>SAE(Stacked Auto-encoders堆叠自动编码器：Sparse Auto-encoders稀疏自动编码器、Denoising Auto-encoders去噪自动编码器、Contractive Auto-encoders 收缩自动编码器)</li>
<li>RBM(RestrictedBoltzmann Machine 受限玻尔兹曼机)</li>
<li>DBN(Deep Belief Network 深度信念网络)</li>
<li>CNN(ConvolutionalNeural Network 卷积神经网络)</li>
<li>Word2Vec(词向量学习模型)</li>
</ul>
<h2 id="DimensionalityReduction(降维)">DimensionalityReduction(降维)</h2>
<ul>
<li>LDA LinearDiscriminant Analysis/Fisher Linear Discriminant 线性判别分析/Fisher线性判别</li>
<li>PCA(Principal Component Analysis 主成分分析)</li>
<li>ICA(IndependentComponent Analysis 独立成分分析)</li>
<li>SVD(Singular Value Decomposition 奇异值分解)</li>
<li>FA(FactorAnalysis 因子分析法)</li>
</ul>
<h2 id="Text_Mining(文本挖掘)">Text Mining(文本挖掘)</h2>
<ul>
<li>VSM(Vector Space Model向量空间模型)</li>
<li>Word2Vec(词向量学习模型)</li>
<li>TF(Term Frequency词频)</li>
<li>TF-IDF(Term Frequency-Inverse DocumentFrequency 词频-逆向文档频率)</li>
<li>MI(MutualInformation 互信息)</li>
<li>ECE(Expected Cross Entropy 期望交叉熵)</li>
<li>QEMI(二次信息熵)</li>
<li>IG(InformationGain 信息增益)</li>
<li>IGR(Information Gain Ratio 信息增益率)</li>
<li>Gini(基尼系数)，x2 Statistic(x2统计量)</li>
<li>TEW(TextEvidence Weight文本证据权)</li>
<li>OR(Odds Ratio 优势率)</li>
<li>N-Gram Model，LSA(Latent Semantic Analysis 潜在语义分析)</li>
<li>PLSA(ProbabilisticLatent Semantic Analysis 基于概率的潜在语义分析)</li>
<li>LDA(Latent DirichletAllocation 潜在狄利克雷模型)</li>
</ul>
<h2 id="Association_Mining(关联挖掘)">Association Mining(关联挖掘)</h2>
<ul>
<li>Apriori</li>
<li>FP-growth(Frequency Pattern Tree Growth 频繁模式树生长算法)</li>
<li>AprioriAll</li>
<li>Spade</li>
</ul>
<h2 id="Recommendation_Engine(推荐引擎)">Recommendation Engine(推荐引擎)</h2>
<ul>
<li>DBR(Demographic-based Recommendation 基于人口统计学的推荐)</li>
<li>CBR(Context-basedRecommendation 基于内容的推荐)</li>
<li>CF(Collaborative Filtering协同过滤)</li>
<li>UCF(User-basedCollaborative Filtering Recommendation 基于用户的协同过滤推荐)</li>
<li>ICF(Item-basedCollaborative Filtering Recommendation 基于项目的协同过滤推荐)</li>
</ul>
<h2 id="Similarity_Measure&amp;Distance_Measure(相似性与距离度量)：">Similarity Measure&amp;Distance Measure(相似性与距离度量)：</h2>
<ul>
<li>Euclidean Distance(欧式距离)</li>
<li>ManhattanDistance(曼哈顿距离)</li>
<li>Chebyshev Distance(切比雪夫距离)</li>
<li>MinkowskiDistance(闵可夫斯基距离)</li>
<li>Standardized Euclidean Distance(标准化欧氏距离)</li>
<li>MahalanobisDistance(马氏距离)</li>
<li>Cos(Cosine 余弦)</li>
<li>HammingDistance/Edit Distance(汉明距离/编辑距离)</li>
<li>JaccardDistance(杰卡德距离)</li>
<li>Correlation Coefficient Distance(相关系数距离)</li>
<li>InformationEntropy(信息熵)</li>
<li>KL(Kullback-Leibler Divergence KL散度/Relative Entropy 相对熵)</li>
</ul>
<h2 id="Optimization(最优化)">Optimization(最优化)</h2>
<ul>
<li>Heuristic Algorithm(启发式算法)</li>
<li>SA(SimulatedAnnealing，模拟退火算法)</li>
<li>GA(genetic algorithm遗传算法)</li>
</ul>
<h3 id="Non-constrainedOptimization(无约束优化)">Non-constrainedOptimization(无约束优化)</h3>
<ul>
<li>Cyclic VariableMethods(变量轮换法)</li>
<li>Pattern Search Methods(模式搜索法)</li>
<li>VariableSimplex Methods(可变单纯形法)</li>
<li>Gradient Descent Methods(梯度下降法)</li>
<li>Newton Methods(牛顿法)</li>
<li>Quasi-NewtonMethods(拟牛顿法)</li>
<li>Conjugate Gradient Methods(共轭梯度法)</li>
</ul>
<h3 id="ConstrainedOptimization(有约束优化)">ConstrainedOptimization(有约束优化)</h3>
<ul>
<li>Approximation Programming Methods(近似规划法)</li>
<li>FeasibleDirection Methods(可行方向法)</li>
<li>Penalty Function Methods(罚函数法)</li>
<li>Multiplier Methods(乘子法)</li>
</ul>
<h2 id="Feature_Selection(特征选择算法)">Feature Selection(特征选择算法)</h2>
<ul>
<li>Mutual Information(互信息)</li>
<li>DocumentFrequence(文档频率)</li>
<li>Information Gain(信息增益)</li>
<li>Chi-squared Test(卡方检验)</li>
<li>Gini(基尼系数)</li>
</ul>
<h2 id="Outlier_Detection(异常点检测算法)">Outlier Detection(异常点检测算法)</h2>
<ul>
<li>Statistic-based(基于统计)</li>
<li>Distance-based(基于距离)</li>
<li>Density-based(基于密度)</li>
<li>Clustering-based(基于聚类)</li>
</ul>
<h2 id="Learning_to_Rank(基于学习的排序)">Learning to Rank(基于学习的排序)</h2>
<ul>
<li>Pointwise：McRank；</li>
<li>Pairwise：RankingSVM，RankNet，Frank，RankBoost；</li>
<li>Listwise：AdaRank，SoftRank，LamdaMART；</li>
</ul>
<h2 id="Tool(工具)">Tool(工具)</h2>
<ul>
<li>MPI，Hadoop生态圈，Spark，BSP，Weka，Mahout，Scikit-learn，PyBrain…</li>
</ul>
<h1 id="End">End</h1>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习基础/">机器学习基础</a>
  </div>

</div>


<div class="article-share" id="share">

<div class="share-jiathis">
  
<div class="jiathis_style_24x24">
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_googleplus"></a>
	<a class="jiathis_button_douban"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
    var jiathis_config={
    data_track_clickback:true,
    sm:"copy,renren,cqq",
    pic:"",
    summary:"",
     ralateuid:{"tsina":"2155417625"},hideMore:false}
    
  </script> 
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js?uid=
" charset="utf-8"></script>      

 </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2015/01/05/编程面试的10大算法概念-常考/" title="编程面试的10大算法概念-常考">
  <strong>上一篇：</strong><br/>
  <span>
  编程面试的10大算法概念-常考</span>
</a>
</div>


<div class="next">
<a href="/2015/01/03/手写数字识别-Kernel Support Vector Machine-博客翻译-毕设系列/"  title="手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列">
 <strong>下一篇：</strong><br/> 
 <span>手写数字识别-Kernel Support Vector Machine-论文翻译-毕设系列
</span>
</a>
</div>

</nav>

	
<section class="comment">
	<div class="ds-thread"></div>
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"tim4chan"};
		(function() {
			var ds = document.createElement('script');
			ds.type = 'text/javascript';ds.async = true;
			ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
			ds.charset = 'UTF-8';
			(document.getElementsByTagName('head')[0] 
			 || document.getElementsByTagName('body')[0]).appendChild(ds);
		})();
		</script>
</section>


</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#说明"><span class="toc-number">1.</span> <span class="toc-text">说明</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Basis(基础)"><span class="toc-number">1.1.</span> <span class="toc-text">Basis(基础)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Common_Distribution(常见分布)"><span class="toc-number">1.2.</span> <span class="toc-text">Common Distribution(常见分布)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Discrete_Distribution(离散型分布)"><span class="toc-number">1.2.1.</span> <span class="toc-text">Discrete Distribution(离散型分布)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Continuous_Distribution_(连续型分布)"><span class="toc-number">1.2.2.</span> <span class="toc-text">Continuous Distribution (连续型分布)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Three_Sampling_Distribution(三大抽样分布)"><span class="toc-number">1.2.3.</span> <span class="toc-text">Three Sampling Distribution(三大抽样分布)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data_Pre-processing(数据预处理)"><span class="toc-number">1.3.</span> <span class="toc-text">Data Pre-processing(数据预处理)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sampling(采样)"><span class="toc-number">1.4.</span> <span class="toc-text">Sampling(采样)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Clustering(聚类)"><span class="toc-number">1.5.</span> <span class="toc-text">Clustering(聚类)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Classification&Regression(分类&回归)"><span class="toc-number">1.6.</span> <span class="toc-text">Classification&Regression(分类&回归)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Effectiveness_Evaluation(分类效果评估)"><span class="toc-number">1.7.</span> <span class="toc-text">Effectiveness Evaluation(分类效果评估)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PGM(Probabilistic_Graphical_Models概率图模型)"><span class="toc-number">1.8.</span> <span class="toc-text">PGM(Probabilistic Graphical Models概率图模型)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NN(Neural_Network神经网络)"><span class="toc-number">1.9.</span> <span class="toc-text">NN(Neural Network神经网络)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep_Learning(深度学习)"><span class="toc-number">1.10.</span> <span class="toc-text">Deep Learning(深度学习)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DimensionalityReduction(降维)"><span class="toc-number">1.11.</span> <span class="toc-text">DimensionalityReduction(降维)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Text_Mining(文本挖掘)"><span class="toc-number">1.12.</span> <span class="toc-text">Text Mining(文本挖掘)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Association_Mining(关联挖掘)"><span class="toc-number">1.13.</span> <span class="toc-text">Association Mining(关联挖掘)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recommendation_Engine(推荐引擎)"><span class="toc-number">1.14.</span> <span class="toc-text">Recommendation Engine(推荐引擎)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Similarity_Measure&Distance_Measure(相似性与距离度量)："><span class="toc-number">1.15.</span> <span class="toc-text">Similarity Measure&Distance Measure(相似性与距离度量)：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Optimization(最优化)"><span class="toc-number">1.16.</span> <span class="toc-text">Optimization(最优化)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Non-constrainedOptimization(无约束优化)"><span class="toc-number">1.16.1.</span> <span class="toc-text">Non-constrainedOptimization(无约束优化)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ConstrainedOptimization(有约束优化)"><span class="toc-number">1.16.2.</span> <span class="toc-text">ConstrainedOptimization(有约束优化)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Feature_Selection(特征选择算法)"><span class="toc-number">1.17.</span> <span class="toc-text">Feature Selection(特征选择算法)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Outlier_Detection(异常点检测算法)"><span class="toc-number">1.18.</span> <span class="toc-text">Outlier Detection(异常点检测算法)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Learning_to_Rank(基于学习的排序)"><span class="toc-number">1.19.</span> <span class="toc-text">Learning to Rank(基于学习的排序)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tool(工具)"><span class="toc-number">1.20.</span> <span class="toc-text">Tool(工具)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#End"><span class="toc-number">2.</span> <span class="toc-text">End</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">Categories</p>
		<ul>
		
			<li><a href="/categories/Django/" title="Django">Django<sup>1</sup></a></li>
		
			<li><a href="/categories/JSP-Review/" title="JSP_Review">JSP_Review<sup>10</sup></a></li>
		
			<li><a href="/categories/Python笔记/" title="Python笔记">Python笔记<sup>1</sup></a></li>
		
			<li><a href="/categories/R-Tutorial/" title="R Tutorial">R Tutorial<sup>4</sup></a></li>
		
			<li><a href="/categories/probability-theory-basic-conception/" title="probability-theory-basic-conception">probability-theory-basic-conception<sup>1</sup></a></li>
		
			<li><a href="/categories/医学图像处理/" title="医学图像处理">医学图像处理<sup>2</sup></a></li>
		
			<li><a href="/categories/原型设计/" title="原型设计">原型设计<sup>1</sup></a></li>
		
			<li><a href="/categories/备忘/" title="备忘">备忘<sup>1</sup></a></li>
		
			<li><a href="/categories/技术开发/" title="技术开发">技术开发<sup>1</sup></a></li>
		
			<li><a href="/categories/数据挖掘与R语言-案例学习/" title="数据挖掘与R语言-案例学习">数据挖掘与R语言-案例学习<sup>4</sup></a></li>
		
			<li><a href="/categories/数据挖掘算法总结/" title="数据挖掘算法总结">数据挖掘算法总结<sup>3</sup></a></li>
		
			<li><a href="/categories/机器学习/" title="机器学习">机器学习<sup>2</sup></a></li>
		
			<li><a href="/categories/概率论笔记/" title="概率论笔记">概率论笔记<sup>2</sup></a></li>
		
			<li><a href="/categories/毕业设计系列/" title="毕业设计系列">毕业设计系列<sup>8</sup></a></li>
		
			<li><a href="/categories/毕设系列/" title="毕设系列">毕设系列<sup>1</sup></a></li>
		
			<li><a href="/categories/算法/" title="算法">算法<sup>1</sup></a></li>
		
			<li><a href="/categories/面试分享/" title="面试分享">面试分享<sup>2</sup></a></li>
		
			<li><a href="/categories/黑马程序员/" title="黑马程序员">黑马程序员<sup>2</sup></a></li>
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			<li><a href="/tags/JSP-网页开发/" title="JSP 网页开发">JSP 网页开发<sup>10</sup></a></li>
		
			<li><a href="/tags/数据挖掘/" title="数据挖掘">数据挖掘<sup>5</sup></a></li>
		
			<li><a href="/tags/R-basics/" title="R basics">R basics<sup>4</sup></a></li>
		
			<li><a href="/tags/SVM入门/" title="SVM入门">SVM入门<sup>2</sup></a></li>
		
			<li><a href="/tags/概率论/" title="概率论">概率论<sup>2</sup></a></li>
		
			<li><a href="/tags/梯度下降法/" title="梯度下降法">梯度下降法<sup>1</sup></a></li>
		
			<li><a href="/tags/机器学习入门基础/" title="机器学习入门基础">机器学习入门基础<sup>1</sup></a></li>
		
			<li><a href="/tags/概率论基本概念/" title="概率论基本概念">概率论基本概念<sup>1</sup></a></li>
		
			<li><a href="/tags/Aprior-Algorithm/" title="Aprior Algorithm">Aprior Algorithm<sup>1</sup></a></li>
		
			<li><a href="/tags/灰度直方图/" title="灰度直方图">灰度直方图<sup>1</sup></a></li>
		
			<li><a href="/tags/FP-growth-tree/" title="FP-growth-tree">FP-growth-tree<sup>1</sup></a></li>
		
			<li><a href="/tags/原型设计/" title="原型设计">原型设计<sup>1</sup></a></li>
		
			<li><a href="/tags/Django-Models/" title="Django-Models">Django-Models<sup>1</sup></a></li>
		
			<li><a href="/tags/面试算法/" title="面试算法">面试算法<sup>1</sup></a></li>
		
			<li><a href="/tags/二值化/" title="二值化">二值化<sup>1</sup></a></li>
		
			<li><a href="/tags/正则表达式/" title="正则表达式">正则表达式<sup>1</sup></a></li>
		
			<li><a href="/tags/SVM/" title="SVM">SVM<sup>1</sup></a></li>
		
			<li><a href="/tags/手写数字-SVM/" title="手写数字 SVM">手写数字 SVM<sup>1</sup></a></li>
		
			<li><a href="/tags/10大基础实用算法/" title="10大基础实用算法">10大基础实用算法<sup>1</sup></a></li>
		
			<li><a href="/tags/手写数字识别-Kernel-Support-Vector-Machine/" title="手写数字识别 Kernel Support Vector Machine">手写数字识别 Kernel Support Vector Machine<sup>1</sup></a></li>
		
		</ul>
</div>


  
  <div class="tagcloudlist">
    <p class="asidetitle">Tag Cloud</p>
    <div class="tagcloudlist clearfix">
       <a href="/tags/10大基础实用算法/" style="font-size: 10.00px;">10大基础实用算法</a><a href="/tags/Aprior-Algorithm/" style="font-size: 10.00px;">Aprior Algorithm</a><a href="/tags/Django-Models/" style="font-size: 10.00px;">Django-Models</a><a href="/tags/FP-growth-tree/" style="font-size: 10.00px;">FP-growth-tree</a><a href="/tags/JSP-网页开发/" style="font-size: 20.00px;">JSP 网页开发</a><a href="/tags/R-basics/" style="font-size: 15.00px;">R basics</a><a href="/tags/SVM/" style="font-size: 10.00px;">SVM</a><a href="/tags/SVM入门/" style="font-size: 12.50px;">SVM入门</a><a href="/tags/linux-C/" style="font-size: 10.00px;">linux C</a><a href="/tags/二值化/" style="font-size: 10.00px;">二值化</a><a href="/tags/单例设计模式/" style="font-size: 10.00px;">单例设计模式</a><a href="/tags/原型设计/" style="font-size: 10.00px;">原型设计</a><a href="/tags/多线程/" style="font-size: 10.00px;">多线程</a><a href="/tags/字符串操作/" style="font-size: 10.00px;">字符串操作</a><a href="/tags/序列/" style="font-size: 10.00px;">序列</a><a href="/tags/感知机/" style="font-size: 10.00px;">感知机</a><a href="/tags/手写数字-SVM/" style="font-size: 10.00px;">手写数字 SVM</a><a href="/tags/手写数字识别-Kernel-Support-Vector-Machine/" style="font-size: 10.00px;">手写数字识别 Kernel Support Vector Machine</a><a href="/tags/数据挖掘/" style="font-size: 17.50px;">数据挖掘</a><a href="/tags/最小二乘法/" style="font-size: 10.00px;">最小二乘法</a><a href="/tags/最小二乘法-论文翻译/" style="font-size: 10.00px;">最小二乘法 论文翻译</a><a href="/tags/有价值的博客记录/" style="font-size: 10.00px;">有价值的博客记录</a><a href="/tags/机器学习入门基础/" style="font-size: 10.00px;">机器学习入门基础</a><a href="/tags/机器学习基础/" style="font-size: 10.00px;">机器学习基础</a><a href="/tags/梯度下降法/" style="font-size: 10.00px;">梯度下降法</a><a href="/tags/概率论/" style="font-size: 12.50px;">概率论</a><a href="/tags/概率论基本概念/" style="font-size: 10.00px;">概率论基本概念</a><a href="/tags/正则表达式/" style="font-size: 10.00px;">正则表达式</a><a href="/tags/灰度直方图/" style="font-size: 10.00px;">灰度直方图</a><a href="/tags/面试算法/" style="font-size: 10.00px;">面试算法</a>
    </div>
  </div>


  <div class="weiboshow">
  <p class="asidetitle">Weibo</p>
<iframe width="100%" height="300" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=300&fansRow=2&ptype=1&speed=300&skin=1&isTitle=1&noborder=1&isWeibo=1&isFans=0&uid=2155417625&verifier=9f994c23&dpc=1"></iframe>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
	  <li><a href="http://zjdian.com/" target="_blank" title="zjdian">中继点</li>
      <li><a href="http://ripeconan.com/" target="_blank" title="ripeconan">Ripeconan</a></li>
      <li><a href="http://hexo.io" target="_blank" title="Hexo">Hexo</a></li>
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello, I&#39;m Tim Chan. <br/>
			Welcome to my personal blog.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/2155417625" target="_blank" class="icon-weibo" title="weibo"></a>
		
		
		<a href="https://github.com/chenyuqing" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		<a href="https://www.douban.com/people/motoleiusre" target="_blank" class="icon-douban" title="豆瓣"></a>
		
		
		
		<a href="mailto:motoleisure@gmail.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Pacman">Jacman</a> © 2015 
		
		<a href="http://tim4chan.com/about" target="_blank" title="Tim Chan">Tim Chan</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>




<script type="text/javascript">
  var duoshuoQuery = {short_name:"乐果404"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 







<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>





<div id="totop">
<a title="Back to Top"><img src="/img/scrollup.png"/></a>
</div>

<script src="/js/totop.js"></script>




  </body>
</html>


<a href="https://github.com/chenyuqing/chenyuqing.github.io"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/652c5b9acfaddf3a9c326fa6bde407b87f7be0f4/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6f72616e67655f6666373630302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a>