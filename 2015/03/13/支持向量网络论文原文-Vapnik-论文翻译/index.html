
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>支持向量网络论文原文-Vapnik-论文翻译 | Tim Chan&#39;s Blog!</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Tim Chan">
    
    <meta name="description" content="摘要：
支持向量网络是一种新的用于二类分类问题的学习机。这个机器(方法)概念地实现了以下想法：非线性的输入向量被映射到高维度的特征空间。在这个特征空间中找出一个线性决策超平面。决策超平面的特殊属性可以保证学习机的强泛化能力。这个支持向量网路的思想在训练资料严格线性可分的情况下已被实现。现在我们来谈一">
    
    
    
    
    <link rel="alternative" href="/atom.xml" title="Tim Chan&#39;s Blog!" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">

</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Tim Chan&#39;s Blog!" title="Tim Chan&#39;s Blog!"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Tim Chan&#39;s Blog!">Tim Chan&#39;s Blog!</a></h1>
				<h2 class="blog-motto">记录生活点滴！</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">首页</a></li>
					
						<li><a href="/archives">归档</a></li>
					
						<li><a href="/about">关于我</a></li>
					
						<li><a href="https://pomotodo.com/app/">ToDo</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:tim4chan.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/03/13/支持向量网络论文原文-Vapnik-论文翻译/" title="支持向量网络论文原文-Vapnik-论文翻译" itemprop="url">支持向量网络论文原文-Vapnik-论文翻译</a>
  </h1>
  <p class="article-author">By
       
		<a href="http://tim4chan.com/about" title="Tim Chan" target="_blank" itemprop="author">Tim Chan</a>
		
  <p class="article-time">
    <time datetime="2015-03-13T10:58:23.000Z" itemprop="datePublished"> Published Mar 13 2015</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#最佳化超平面"><span class="toc-number">2.</span> <span class="toc-text">最佳化超平面</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#最佳超平面算法"><span class="toc-number">2.1.</span> <span class="toc-text">最佳超平面算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#软间隔超平面"><span class="toc-number">3.</span> <span class="toc-text">软间隔超平面</span></a></li></ol>
		
		</div>
		
		<p><img src="/img/paperBlog/Support-Vector-Networks/head.png" alt=""></p>
<ul>
<li><strong>摘要</strong>：<ul>
<li>支持向量网络是一种新的用于二类分类问题的学习机。这个机器(方法)概念地实现了以下想法：非线性的输入向量被映射到高维度的特征空间。在这个特征空间中找出一个线性决策超平面。决策超平面的特殊属性可以保证学习机的强泛化能力。这个支持向量网路的思想在训练资料严格线性可分的情况下已被实现。现在我们来谈一下在训练资料非线性可分的情况下的结果。</li>
<li>支持向量网络的高泛化能力是利用多项式输入转换。我们同样比较了支持向量网络和和其他经典的学习算法在OCR(光学字符识别)这个基准上的表现。</li>
</ul>
</li>
<li><strong>关键字</strong>：<ul>
<li>模式识别， 有效的学习算法， 神经网络， 径向基函数分类器， 多类分类器</li>
</ul>
</li>
</ul>
<h2 id="简介">简介</h2>
<ul>
<li>60多年前R.A. Fisher(Fisher, 1936)提出了模式识别的第一个算法。有两个服从正态分布的模型，<img src="/img/paperBlog/Support-Vector-Networks/01/01.PNG" alt="">和<img src="/img/paperBlog/Support-Vector-Networks/01/02.PNG" alt="">，n维向量X，其中均值向量分别是m1和m2，方差分别是<img src="/img/paperBlog/Support-Vector-Networks/01/03.PNG" alt="">和<img src="/img/paperBlog/Support-Vector-Networks/01/04.PNG" alt="">，最后得到的最优解(贝叶斯)是一个二次规划函数：<br><img src="/img/paperBlog/Support-Vector-Networks/01/05.PNG" alt=""></li>
<li>若果<img src="/img/paperBlog/Support-Vector-Networks/01/06.PNG" alt="">，那么上式化简为一个线性函数：<br><img src="/img/paperBlog/Support-Vector-Networks/01/07.PNG" alt=""></li>
<li>要解式子(1)中的二次规划函数，必须有<img src="/img/paperBlog/Support-Vector-Networks/01/08.PNG" alt="">个自由参数。要解式子(2)中线性函数仅仅要n个自由参数。观测量的数量小(比如说小于<img src="/img/paperBlog/Support-Vector-Networks/01/09.PNG" alt="">个)估算<img src="/img/paperBlog/Support-Vector-Networks/01/10.PNG" alt="">个参数是不可靠的。因此Fisher推荐，即使是在<img src="/img/paperBlog/Support-Vector-Networks/01/11.PNG" alt="">的情况下，仍然对线性判别函数(2)使用以下<img src="/img/paperBlog/Support-Vector-Networks/01/12.PNG" alt="">的形式：<br><img src="/img/paperBlog/Support-Vector-Networks/01/13.PNG" alt=""></li>
<li>上式中的<img src="/img/paperBlog/Support-Vector-Networks/01/14.PNG" alt="">是一个常量。Fisher另外推荐了当两个分布不是服从正态的时候，利用一个线性决策函数。</li>
<li>模式识别的算法最开始就和线性决策超平面的构建有关。</li>
<li><img src="/img/paperBlog/Support-Vector-Networks/01/15.PNG" alt=""></li>
<li>在1962年Rosenblatt(Rosenblatt, 1962)发明了一种新型的学习机：感知机或者神经网络。感知机包含多个相连的神经元，每个神经元实现一个分离超平面，所以整个感知机实现了分段的线性分离超平面。见图Fig.1。</li>
<li>在Rosenblatt时期还没有算法通过调整网络的权值来最小化向量集的错误。根据其他权值的固定值，输入向量被非线性地转换到特征空间Z中,在单元的最后一层。在这个空间中一个线性决策函数被构造：<br><img src="/img/paperBlog/Support-Vector-Networks/01/16.PNG" alt=""></li>
<li>通过调节从第i层隐藏层到输出单元的<img src="/img/paperBlog/Support-Vector-Networks/01/17.PNG" alt="">的权值以最小化在整个训练资料上的一些误差。根据Rosenblatt的方法的结果来看，决策规则的构造再一次联系到信息超平面的构造，在某些空间上。</li>
<li>第一次出现一个算法允许通过调整神经网络的权值来最小化属于模式识别问题的向量集的局部误差是在1986年,(Rumelhart, Hinton &amp; Williams, 1986, 1987; Parker, 1985; LeCun 1985)因为那个时候发现了反向传播算法。它的解法是一个轻微修改的神经元的数学模型。所以，神经网络实现了“分段线性类型”的决策函数。</li>
<li>在本文中，我们构造一个新型的学习机(方法)，所谓的“支持向量网络”。支持向量网络实现了一下想法：它通过一些事先选择好的非线性的映射规则把输入向量映射到高维度的特征空间Z。在这个空间当中，通过一些特殊属性来构造线性决策超平面来保证网络的高泛化能力。</li>
<li><img src="/img/paperBlog/Support-Vector-Networks/01/18.PNG" alt=""></li>
<li>例子：要求得二次多项式的决策超平面，可以创建一个特征空间Z，它有 N= <img src="/img/paperBlog/Support-Vector-Networks/01/08.PNG" alt="">个坐标形式：<br><img src="/img/paperBlog/Support-Vector-Networks/01/19.PNG" alt=""></li>
<li>上面的方法中有两个新的问题：一个是概念上的，一个是技术上的。概念上的问题是怎么才能找到一个推广能力较好的分离超平面：特征空间的维数将会很大，而且并不是所有的可分离训练资料的超平面都有很好的推广能力。然后技术上的问题是面对如此高维的空间，怎么简化计算量：在一个200维德空间中构造一个4次方或者5次方的多项式可能需要构造一个数以数以亿计的维数的空间。</li>
<li>概念上的问题在1965(Vapnik, 1982)被解决了，鉴于<em>为线性可分的类寻找最佳化的分离超平面</em>这个case.这里定义的最佳化的超平面是两个可分的向量中寻找最大的分类间隔，看Fig.2.被证明说要构造这样一个最佳化的超平面只需要很少的训练数据，这些数据就被称为<em>支撑向量</em>，它们是用来决定间隔的。资料表明，如果训练资料被一个最佳化的超平面完美无误地分离，那么在测试例子中预测新数据的误差期望值等于支持向量的数量的期望值和训练向量的数量的比：<br><img src="/img/paperBlog/Support-Vector-Networks/01/20.PNG" alt=""></li>
<li>注意到这个约束并没有明显的包含可分空间的维数。这个约束遵循这个规则的：如果构造最佳化的超平面包含的支持向量的数量越少，那么这个模型的泛化能力就越高—即使是在无穷的维数空间中。在Section 5我们会通过一个实际生活问题说明上面(5)式子的比值可以低到0.03，而且这个最佳化超平面在数以亿计的维数的特征空间中的推广能力很好。</li>
<li>让<br><img src="/img/paperBlog/Support-Vector-Networks/01/21.PNG" alt=""></li>
<li>作为空间中最佳化超平面的表示。我们会把特征空间中的最佳化超平面的权值<img src="/img/paperBlog/Support-Vector-Networks/01/22.PNG" alt="">写成支持向量的线性组合式<br><img src="/img/paperBlog/Support-Vector-Networks/01/23.PNG" alt=""></li>
<li>特征空间中的线性决策函数<img src="/img/paperBlog/Support-Vector-Networks/01/26.PNG" alt="">会相应地变成以下形式：<img src="/img/paperBlog/Support-Vector-Networks/01/24.PNG" alt=""></li>
<li><img src="/img/paperBlog/Support-Vector-Networks/01/27.PNG" alt="">表示的是再特征空间中的支持向量zi和z的点积。决策函数能够被描述为一个两层的网络。(Fig.3.)</li>
<li>然而，即使最佳化超平面的推广能力比较好，但是关于怎样处理高维度空间的技术的问题还没解决。在1992年(Boser, Guyon, &amp; Vapnik, 1992)，构造决策函数的操作顺序是可以互换的：我们可以先比较输入空间中的两个向量(比如，计算它们的点积，或者一些距离测量)对结果的值做非线性转换，而不是拿特征空间中两个点积的向量做非线性的转换。这样促成了更多分类的决策超平面的构造，例如，任意次方的多项式决策超平面。我们把这种类型的学习机叫做支持向量网络。</li>
<li>支持向量网络的技巧当初是为了毫无误差地找到更精准的分类训练数据的超平面。在这篇文章当中，我们对支持向量网络进行拓展，拓展到当不能毫无误差的进行分类数据的情况下也能使用。在这种情形之下，我们把支持向量网络当成一种新的学习机。一种像神经网络一样更强大更通用的学习机。在Section 5我们会对在一个高维空间(维度256)，多项式次方高达7的情形下，支持向量网络的泛化能力还能有多好进行说明。这种学习机的表现可以与那些经典的学习机(像线性分类器，k邻近分类器和神经网络等)相媲美。Section 2，3和4主要讲算法的推导和它的一些属性的讨论。关于推导的细节请看附录部分。<br><img src="/img/paperBlog/Support-Vector-Networks/01/25.PNG" alt=""></li>
</ul>
<h2 id="最佳化超平面">最佳化超平面</h2>
<ul>
<li>在这个section当中，让我们来回顾一下0误差分离训练资料的最佳化超平面的方法(Vapnik, 1982).而在下一个section，我们介绍软间隔的记号，它允许在分类的过程当中存在误差。</li>
</ul>
<h3 id="最佳超平面算法">最佳超平面算法</h3>
<ul>
<li>训练模式的标签集<br><img src="/img/paperBlog/Support-Vector-Networks/02/01.PNG" alt=""></li>
<li>被认为是线性可分的，如果向量W和标量b满足以下不等式条件：<br><img src="/img/paperBlog/Support-Vector-Networks/02/02.PNG" alt=""></li>
<li>被认为说是对(8)中的所有的训练集都是有效的。然后把(9)中的不等式写成一下形式：<br><img src="/img/paperBlog/Support-Vector-Networks/02/04.PNG" alt=""></li>
<li><img src="/img/paperBlog/Support-Vector-Networks/02/03.PNG" alt=""></li>
<li>最佳化超平面是：<br><img src="/img/paperBlog/Support-Vector-Networks/02/05.PNG" alt=""></li>
<li>它是唯一一个把训练资料分离出最大间隔：它保证了两个不同类别的训练向量映射在<img src="/img/paperBlog/Support-Vector-Networks/02/06.PNG" alt="">方向上的距离是最大的。回顾Fig.2.这个距离<img src="/img/paperBlog/Support-Vector-Networks/02/07.PNG" alt="">表示如下：<br><img src="/img/paperBlog/Support-Vector-Networks/02/08.PNG" alt=""></li>
<li>最佳化超平面<img src="/img/paperBlog/Support-Vector-Networks/02/09.PNG" alt="">是使得(12)中距离最大的参数。它符合(12)和(10)的约束<img src="/img/paperBlog/Support-Vector-Networks/02/10.PNG" alt=""></li>
<li>这就是说最佳化超平面在符合(10)式当中的约束的条件下是唯一一个可以最小化<img src="/img/paperBlog/Support-Vector-Networks/02/11.PNG" alt="">的.所以构造最佳化超平面的问题就是一个二次规划问题。</li>
<li><img src="/img/paperBlog/Support-Vector-Networks/02/13.PNG" alt="">当中的向量<img src="/img/paperBlog/Support-Vector-Networks/02/12.PNG" alt="">学术上被称为<em>支持向量</em>。在附录A.1中，我们说明了能够决定最佳化超平面的向量<img src="/img/paperBlog/Support-Vector-Networks/02/14.PNG" alt="">可以写成一个训练向量的线性组合形式：<img src="/img/paperBlog/Support-Vector-Networks/02/15.PNG" alt=""></li>
<li>(14)中当<img src="/img/paperBlog/Support-Vector-Networks/02/16.PNG" alt="">.因为<img src="/img/paperBlog/Support-Vector-Networks/02/17.PNG" alt="">仅仅是符合支持向量(看附录)，(14)当中的表达式是<img src="/img/paperBlog/Support-Vector-Networks/02/14.PNG" alt="">的简写形式。我们也说明了要找参数<img src="/img/paperBlog/Support-Vector-Networks/02/18.PNG" alt="">的向量：<br><img src="/img/paperBlog/Support-Vector-Networks/02/19.PNG" alt=""></li>
<li>必须要解决以下的二次规划问题：<br><img src="/img/paperBlog/Support-Vector-Networks/02/20.PNG" alt=""></li>
<li>其中<img src="/img/paperBlog/Support-Vector-Networks/02/21.PNG" alt="">满足的约束条件是：<br><img src="/img/paperBlog/Support-Vector-Networks/02/22.PNG" alt=""></li>
<li>其中<img src="/img/paperBlog/Support-Vector-Networks/02/23.PNG" alt="">是一个<img src="/img/paperBlog/Support-Vector-Networks/02/24.PNG" alt="">维的单位向量，<img src="/img/paperBlog/Support-Vector-Networks/02/25.PNG" alt="">是一个<img src="/img/paperBlog/Support-Vector-Networks/02/24.PNG" alt="">维的标签向量，<img src="/img/paperBlog/Support-Vector-Networks/02/26.PNG" alt="">是一个带元素的对称的<img src="/img/paperBlog/Support-Vector-Networks/02/27.PNG" alt="">矩阵<br><img src="/img/paperBlog/Support-Vector-Networks/02/28.PNG" alt=""></li>
<li>(16)当中的不等式描述的是非负象限。所以我们在(17)的约束条件下最大化(15)中的二次规划式。</li>
<li>当(8)中的训练资料可以0误差的分离时，我们同样在附录中进行了说明，(15)中的最大值，<img src="/img/paperBlog/Support-Vector-Networks/02/29.PNG" alt="">对和(13)中的最大间隔<img src="/img/paperBlog/Support-Vector-Networks/02/35.PNG" alt="">的关系：<br><img src="/img/paperBlog/Support-Vector-Networks/02/30.PNG" alt=""></li>
<li>对于某些<img src="/img/paperBlog/Support-Vector-Networks/02/31.PNG" alt="">和大的常量<img src="/img/paperBlog/Support-Vector-Networks/02/32.PNG" alt="">，不等式<br><img src="/img/paperBlog/Support-Vector-Networks/02/33.PNG" alt=""></li>
<li>是合理的，有一个可以断言的是所有的可分离训练资料(8)的超平面都满足<br><img src="/img/paperBlog/Support-Vector-Networks/02/34.PNG" alt=""></li>
<li>如果(8)中的训练资料不能被一个超平面分离，那么两个模式类别之间的间隔将会非常小，导致函数<img src="/img/paperBlog/Support-Vector-Networks/02/36.PNG" alt="">的值非常大。在约束条件(16)和(17)下最大化函数(15)的值，其中一个达到最大值时(这种情况是其中一个通过最大间隔<img src="/img/paperBlog/Support-Vector-Networks/02/35.PNG" alt="">构建了一个超平面)，或者其中一个找到了最大值超过了给定的常量<img src="/img/paperBlog/Support-Vector-Networks/02/32.PNG" alt="">(这种情况是训练资料的分离超平面比<img src="/img/paperBlog/Support-Vector-Networks/02/37.PNG" alt="">还要大是不可能的)。</li>
<li>在约束条件(16)和(17)下最大化函数(15)的问题很有效地通过以下模式解决。把训练资料合理的分成多个不大的部分。首先利用第一部分的训练资料来解决二次规划的问题。对于这样的处理会有两种可能的结果：这部分的训练资料不能找打一个可分离的超平面(这样的话整个资料也是找不到可分离的超平面的)，或者在第一部分的训练资料中就找到了最佳化的分离超平面。</li>
<li>如果是在第一部分的训练资料中就找到了分离超平面，我们把它称作向量<img src="/img/paperBlog/Support-Vector-Networks/02/38.PNG" alt="">，让它来最大化函数(15).在向量<img src="/img/paperBlog/Support-Vector-Networks/02/38.PNG" alt="">当中有一些值是等于0的。它们对应于这部分资料的非支持向量。创建一个新的训练资料集，其中包含第一部分资料的支持向量和第二部分资料的那些不符合约束(10)的向量，其中<img src="/img/paperBlog/Support-Vector-Networks/02/39.PNG" alt="">是由<img src="/img/paperBlog/Support-Vector-Networks/02/38.PNG" alt="">决定的。在这个新的资料集当中创造了一个新的函数<img src="/img/paperBlog/Support-Vector-Networks/02/40.PNG" alt="">和这个函数在<img src="/img/paperBlog/Support-Vector-Networks/02/41.PNG" alt="">处达到最大。然后重复这样的做法，覆盖到所有的训练资料中，不断增加新的解法向量<img src="/img/paperBlog/Support-Vector-Networks/02/31.PNG" alt="">，如果找不到0误差的分离超平面，或者对所有训练资料可以构造一个最佳化分离超平面<img src="/img/paperBlog/Support-Vector-Networks/02/42.PNG" alt="">.请注意，在这个过程当中，函数<img src="/img/paperBlog/Support-Vector-Networks/02/36.PNG" alt="">的值是单调递增的，因为越来越多的训练向量被划分为最佳化，导致两个类别之间的分隔越来越小。</li>
</ul>
<h2 id="软间隔超平面">软间隔超平面</h2>
<ul>
<li>考虑到那种不能0误差的把训练资料分离的情况。这样的话，我们想说要达到误差的最小化来分离资料。要正式地表达这个，让我们先引入一些非负变量<img src="/img/paperBlog/Support-Vector-Networks/03/01.PNG" alt=""></li>
<li>我们现在最小化函数<br><img src="/img/paperBlog/Support-Vector-Networks/03/02.PNG" alt=""></li>
<li>其中<img src="/img/paperBlog/Support-Vector-Networks/03/03.PNG" alt="">，约束于<br><img src="/img/paperBlog/Support-Vector-Networks/03/04.PNG" alt=""></li>
<li><img src="/img/paperBlog/Support-Vector-Networks/03/05.PNG" alt="">足够小，函数(21)描述的是训练错误的个数。</li>
<li>最小化(21)，我们要找出一些最小的训练错误的子集：<br><img src="/img/paperBlog/Support-Vector-Networks/03/06.PNG" alt=""></li>
<li>如果这些误差资料不包含在训练资料中，那么训练资料就可以毫无误差的进行分离，并且在两个类别之间找到一个超平面。</li>
<li>这个想法可以正式的表达为：最小化函数<br><img src="/img/paperBlog/Support-Vector-Networks/03/07.PNG" alt=""></li>
<li>约束条件为(22)和(23)，其中<img src="/img/paperBlog/Support-Vector-Networks/03/08.PNG" alt="">是一个单调的凸函数，<img src="/img/paperBlog/Support-Vector-Networks/03/09.PNG" alt="">是一个常量。</li>
<li>足够大的<img src="/img/paperBlog/Support-Vector-Networks/03/09.PNG" alt="">和足够小的<img src="/img/paperBlog/Support-Vector-Networks/03/05.PNG" alt="">，在约束条件(22)和(23)下的最小化函数(24)的向量<img src="/img/paperBlog/Support-Vector-Networks/03/10.PNG" alt="">和常数<img src="/img/paperBlog/Support-Vector-Networks/03/11.PNG" alt="">，可以决定一个超平面，这个超平面是最小化在训练集上的错误个数和把剩余的元素利用最大间隔进行分离。</li>
<li>注意到，在训练集上构造一个能够最小化错误数的超平面是一个正常的NPC问题(因不能用多项式算法而使问题无法解决的；非完全多项式).为避免我们的问题出现NPC问题，我们设定<img src="/img/paperBlog/Support-Vector-Networks/03/12.PNG" alt=""></li>
</ul>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


</div>


<div class="article-share" id="share">

<div class="share-jiathis">
  
<div class="jiathis_style_24x24">
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_googleplus"></a>
	<a class="jiathis_button_douban"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
    var jiathis_config={
    data_track_clickback:true,
    sm:"copy,renren,cqq",
    pic:"",
    summary:"",
     ralateuid:{"tsina":"2155417625"},hideMore:false}
    
  </script> 
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js?uid=
" charset="utf-8"></script>      

 </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2015/04/06/1-1-随机事件-样本空间/" title="1.1-随机事件-样本空间">
  <strong>上一篇：</strong><br/>
  <span>
  1.1-随机事件-样本空间</span>
</a>
</div>


<div class="next">
<a href="/2015/03/11/KKT条件论文-论文翻译/"  title="非线性规划-KKT条件论文-论文翻译">
 <strong>下一篇：</strong><br/> 
 <span>非线性规划-KKT条件论文-论文翻译
</span>
</a>
</div>

</nav>

	

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#最佳化超平面"><span class="toc-number">2.</span> <span class="toc-text">最佳化超平面</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#最佳超平面算法"><span class="toc-number">2.1.</span> <span class="toc-text">最佳超平面算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#软间隔超平面"><span class="toc-number">3.</span> <span class="toc-text">软间隔超平面</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">Categories</p>
		<ul>
		
			<li><a href="/categories/Django/" title="Django">Django<sup>1</sup></a></li>
		
			<li><a href="/categories/JSP-Review/" title="JSP_Review">JSP_Review<sup>10</sup></a></li>
		
			<li><a href="/categories/Python笔记/" title="Python笔记">Python笔记<sup>1</sup></a></li>
		
			<li><a href="/categories/R-Tutorial/" title="R Tutorial">R Tutorial<sup>4</sup></a></li>
		
			<li><a href="/categories/probability-theory-basic-conception/" title="probability-theory-basic-conception">probability-theory-basic-conception<sup>1</sup></a></li>
		
			<li><a href="/categories/医学图像处理/" title="医学图像处理">医学图像处理<sup>2</sup></a></li>
		
			<li><a href="/categories/原型设计/" title="原型设计">原型设计<sup>1</sup></a></li>
		
			<li><a href="/categories/备忘/" title="备忘">备忘<sup>1</sup></a></li>
		
			<li><a href="/categories/技术开发/" title="技术开发">技术开发<sup>1</sup></a></li>
		
			<li><a href="/categories/数据挖掘与R语言-案例学习/" title="数据挖掘与R语言-案例学习">数据挖掘与R语言-案例学习<sup>4</sup></a></li>
		
			<li><a href="/categories/数据挖掘算法总结/" title="数据挖掘算法总结">数据挖掘算法总结<sup>3</sup></a></li>
		
			<li><a href="/categories/机器学习/" title="机器学习">机器学习<sup>2</sup></a></li>
		
			<li><a href="/categories/概率论与数理统计-南京大学/" title="概率论与数理统计---南京大学">概率论与数理统计---南京大学<sup>1</sup></a></li>
		
			<li><a href="/categories/概率论笔记/" title="概率论笔记">概率论笔记<sup>2</sup></a></li>
		
			<li><a href="/categories/毕业设计系列/" title="毕业设计系列">毕业设计系列<sup>8</sup></a></li>
		
			<li><a href="/categories/毕设系列/" title="毕设系列">毕设系列<sup>1</sup></a></li>
		
			<li><a href="/categories/算法/" title="算法">算法<sup>1</sup></a></li>
		
			<li><a href="/categories/面试分享/" title="面试分享">面试分享<sup>2</sup></a></li>
		
			<li><a href="/categories/黑马程序员/" title="黑马程序员">黑马程序员<sup>2</sup></a></li>
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			<li><a href="/tags/JSP-网页开发/" title="JSP 网页开发">JSP 网页开发<sup>10</sup></a></li>
		
			<li><a href="/tags/数据挖掘/" title="数据挖掘">数据挖掘<sup>5</sup></a></li>
		
			<li><a href="/tags/R-basics/" title="R basics">R basics<sup>4</sup></a></li>
		
			<li><a href="/tags/SVM入门/" title="SVM入门">SVM入门<sup>2</sup></a></li>
		
			<li><a href="/tags/概率论/" title="概率论">概率论<sup>2</sup></a></li>
		
			<li><a href="/tags/概率论基本概念/" title="概率论基本概念">概率论基本概念<sup>1</sup></a></li>
		
			<li><a href="/tags/梯度下降法/" title="梯度下降法">梯度下降法<sup>1</sup></a></li>
		
			<li><a href="/tags/机器学习入门基础/" title="机器学习入门基础">机器学习入门基础<sup>1</sup></a></li>
		
			<li><a href="/tags/最小二乘法-论文翻译/" title="最小二乘法 论文翻译">最小二乘法 论文翻译<sup>1</sup></a></li>
		
			<li><a href="/tags/最小二乘法/" title="最小二乘法">最小二乘法<sup>1</sup></a></li>
		
			<li><a href="/tags/FP-growth-tree/" title="FP-growth-tree">FP-growth-tree<sup>1</sup></a></li>
		
			<li><a href="/tags/Aprior-Algorithm/" title="Aprior Algorithm">Aprior Algorithm<sup>1</sup></a></li>
		
			<li><a href="/tags/手写数字-SVM/" title="手写数字 SVM">手写数字 SVM<sup>1</sup></a></li>
		
			<li><a href="/tags/手写数字识别-Kernel-Support-Vector-Machine/" title="手写数字识别 Kernel Support Vector Machine">手写数字识别 Kernel Support Vector Machine<sup>1</sup></a></li>
		
			<li><a href="/tags/感知机/" title="感知机">感知机<sup>1</sup></a></li>
		
			<li><a href="/tags/Django-Models/" title="Django-Models">Django-Models<sup>1</sup></a></li>
		
			<li><a href="/tags/二值化/" title="二值化">二值化<sup>1</sup></a></li>
		
			<li><a href="/tags/字符串操作/" title="字符串操作">字符串操作<sup>1</sup></a></li>
		
			<li><a href="/tags/机器学习基础/" title="机器学习基础">机器学习基础<sup>1</sup></a></li>
		
			<li><a href="/tags/灰度直方图/" title="灰度直方图">灰度直方图<sup>1</sup></a></li>
		
		</ul>
</div>


  
  <div class="tagcloudlist">
    <p class="asidetitle">Tag Cloud</p>
    <div class="tagcloudlist clearfix">
       <a href="/tags/10大基础实用算法/" style="font-size: 10.00px;">10大基础实用算法</a><a href="/tags/Aprior-Algorithm/" style="font-size: 10.00px;">Aprior Algorithm</a><a href="/tags/Django-Models/" style="font-size: 10.00px;">Django-Models</a><a href="/tags/FP-growth-tree/" style="font-size: 10.00px;">FP-growth-tree</a><a href="/tags/JSP-网页开发/" style="font-size: 20.00px;">JSP 网页开发</a><a href="/tags/R-basics/" style="font-size: 15.00px;">R basics</a><a href="/tags/SVM/" style="font-size: 10.00px;">SVM</a><a href="/tags/SVM入门/" style="font-size: 12.50px;">SVM入门</a><a href="/tags/linux-C/" style="font-size: 10.00px;">linux C</a><a href="/tags/二值化/" style="font-size: 10.00px;">二值化</a><a href="/tags/单例设计模式/" style="font-size: 10.00px;">单例设计模式</a><a href="/tags/原型设计/" style="font-size: 10.00px;">原型设计</a><a href="/tags/多线程/" style="font-size: 10.00px;">多线程</a><a href="/tags/字符串操作/" style="font-size: 10.00px;">字符串操作</a><a href="/tags/序列/" style="font-size: 10.00px;">序列</a><a href="/tags/感知机/" style="font-size: 10.00px;">感知机</a><a href="/tags/手写数字-SVM/" style="font-size: 10.00px;">手写数字 SVM</a><a href="/tags/手写数字识别-Kernel-Support-Vector-Machine/" style="font-size: 10.00px;">手写数字识别 Kernel Support Vector Machine</a><a href="/tags/数据挖掘/" style="font-size: 17.50px;">数据挖掘</a><a href="/tags/最小二乘法/" style="font-size: 10.00px;">最小二乘法</a><a href="/tags/最小二乘法-论文翻译/" style="font-size: 10.00px;">最小二乘法 论文翻译</a><a href="/tags/有价值的博客记录/" style="font-size: 10.00px;">有价值的博客记录</a><a href="/tags/机器学习入门基础/" style="font-size: 10.00px;">机器学习入门基础</a><a href="/tags/机器学习基础/" style="font-size: 10.00px;">机器学习基础</a><a href="/tags/梯度下降法/" style="font-size: 10.00px;">梯度下降法</a><a href="/tags/概率论/" style="font-size: 12.50px;">概率论</a><a href="/tags/概率论基本概念/" style="font-size: 10.00px;">概率论基本概念</a><a href="/tags/正则表达式/" style="font-size: 10.00px;">正则表达式</a><a href="/tags/灰度直方图/" style="font-size: 10.00px;">灰度直方图</a><a href="/tags/随机事件与样本空间/" style="font-size: 10.00px;">随机事件与样本空间</a><a href="/tags/面试算法/" style="font-size: 10.00px;">面试算法</a>
    </div>
  </div>


  <div class="weiboshow">
  <p class="asidetitle">Weibo</p>
<iframe width="100%" height="300" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=300&fansRow=2&ptype=1&speed=300&skin=1&isTitle=1&noborder=1&isWeibo=1&isFans=0&uid=2155417625&verifier=9f994c23&dpc=1"></iframe>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
	  <li><a href="http://zjdian.com/" target="_blank" title="zjdian">中继点</li>
      <li><a href="http://ripeconan.com/" target="_blank" title="ripeconan">Ripeconan</a></li>
      <li><a href="http://hexo.io" target="_blank" title="Hexo">Hexo</a></li>
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello, I&#39;m Tim Chan. <br/>
			Welcome to my personal blog.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/2155417625" target="_blank" class="icon-weibo" title="weibo"></a>
		
		
		<a href="https://github.com/chenyuqing" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		<a href="https://www.douban.com/people/motoleiusre" target="_blank" class="icon-douban" title="豆瓣"></a>
		
		
		
		<a href="mailto:motoleisure@gmail.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Pacman">Jacman</a> © 2015 
		
		<a href="http://tim4chan.com/about" target="_blank" title="Tim Chan">Tim Chan</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>




<script type="text/javascript">
  var duoshuoQuery = {short_name:"乐果404"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 







<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>





<div id="totop">
<a title="Back to Top"><img src="/img/scrollup.png"/></a>
</div>

<script src="/js/totop.js"></script>




<script type="text/javascript">
var duoshuoQuery = {short_name:"乐果404"};
        (function() {
                var ds = document.createElement('script');
                ds.type = 'text/javascript';ds.async = true;
                ds.src = 'http://static.duoshuo.com/embed.js';
                ds.charset = 'UTF-8';
                (document.getElementsByTagName('head')[0]
                || document.getElementsByTagName('body')[0]).appendChild(ds);
        })();
</script>
  </body>
</html>


<a href="https://github.com/chenyuqing/chenyuqing.github.io"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/652c5b9acfaddf3a9c326fa6bde407b87f7be0f4/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6f72616e67655f6666373630302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a>